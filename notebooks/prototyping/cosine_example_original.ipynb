{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that are needed for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms import Spectrum\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "ref_spectra_df_path = Path(\"/Users/yoanngloaguen/Desktop/example_dataset_tornike.csv\")\n",
    "if ref_spectra_df_path.exists():\n",
    "    ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "else:\n",
    "    ref_spectra_df = get_reference_spectra(0)\n",
    "    ref_spectra_df.to_csv(ref_spectra_df_path, index=False)\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    spectra = []\n",
    "    for index, row in spectra_df.iterrows():\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                  'precursor_mz': precursor_mz, \n",
    "                                  'smiles': smiles, \n",
    "                                  'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        if sp is not None:\n",
    "            spectra.append(sp)\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the \"most\" time consuming part of the code. \n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def score_best_matches(matching_pairs: np.ndarray, spec1: np.ndarray,\n",
    "                       spec2: np.ndarray, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0) -> Tuple[float, int]:\n",
    "    \"\"\"Calculate cosine-like score by multiplying matches. Does require a sorted\n",
    "    list of matching peaks (sorted by intensity product).\"\"\"\n",
    "    score = float(0.0)\n",
    "    used_matches = int(0)\n",
    "    used1 = set()\n",
    "    used2 = set()\n",
    "    for i in range(matching_pairs.shape[0]):\n",
    "        if not matching_pairs[i, 0] in used1 and not matching_pairs[i, 1] in used2:\n",
    "            score += matching_pairs[i, 2]\n",
    "            used1.add(matching_pairs[i, 0])  # Every peak can only be paired once\n",
    "            used2.add(matching_pairs[i, 1])  # Every peak can only be paired once\n",
    "            used_matches += 1\n",
    "\n",
    "    # Normalize score:\n",
    "    spec1_power = spec1[:, 0] ** mz_power * spec1[:, 1] ** intensity_power\n",
    "    spec2_power = spec2[:, 0] ** mz_power * spec2[:, 1] ** intensity_power\n",
    "\n",
    "\n",
    "    score = score/(np.sum(spec1_power ** 2) ** 0.5 * np.sum(spec2_power ** 2) ** 0.5)\n",
    "    return score, used_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use case\n",
    "\n",
    "Here I am intentionally creating different use case that we might encounter in prod:\n",
    "\n",
    "    - Spectra of different lengths\n",
    "\n",
    "    - Spectra containing several very close m/z which will fall within the tolerance window (spectrum 4 mz:100 and mz:100.001)\n",
    "    \n",
    "    - This is not covered here but we could also have different number of spectra in references and queries - This will always happen in prod actually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-11 11:35:56,702:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-11 11:35:56,704:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-11 11:35:56,704:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-11 11:35:56,705:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n"
     ]
    }
   ],
   "source": [
    "spectrum_1 = Spectrum(mz=np.array([100, 150, 200., 203, 234]),\n",
    "                      intensities=np.array([0.7, 0.2, 0.1, 0.1, 0.1]),\n",
    "                      metadata={'id': 'spectrum1'})\n",
    "spectrum_2 = Spectrum(mz=np.array([100, 140, 190., 210]),\n",
    "                      intensities=np.array([0.4, 0.2, 0.1, 0.1]),\n",
    "                      metadata={'id': 'spectrum2'})\n",
    "spectrum_3 = Spectrum(mz=np.array([110, 140, 195.]),\n",
    "                      intensities=np.array([0.6, 0.2, 0.1]),\n",
    "                      metadata={'id': 'spectrum3'})\n",
    "spectrum_4 = Spectrum(mz=np.array([100, 100.001, 150, 200.]),\n",
    "                      intensities=np.array([0.6, 0.1, 0.3, 0.6]),\n",
    "                      metadata={'id': 'spectrum4'})\n",
    "references = [spectrum_1, spectrum_3]\n",
    "queries = [spectrum_2, spectrum_4]\n",
    "\n",
    "large_references = get_ref_spectra_from_df(ref_spectra_df.head(100000)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7977240352174655, 1)\n",
      "(0.7968798037362897, 3)\n",
      "(0.13318543164240537, 1)\n",
      "No matching pairs found\n"
     ]
    }
   ],
   "source": [
    "# In the matchms library, the cosineGreedy function and Score object would take care of the this for loop\n",
    "# There may be some extra data prep and filter as well but we can ignore that for now\n",
    "# and reorganise the data to return it as one single output.\n",
    "# Here is an example of how it would work by default:\n",
    "\n",
    "# Start example ------------\n",
    "\n",
    "# import numpy as np\n",
    "# from matchms.similarity import CosineGreedy\n",
    "# from matchms import calculate_scores\n",
    "\n",
    "# similarity_measure = CosineGreedy()\n",
    "# scores = calculate_scores(references, queries, similarity_measure)\n",
    "\n",
    "# This only for printing the results\n",
    "# for (reference, query, score) in scores:\n",
    "#     print(f\"Cosine score between {reference.get('id')} and {query.get('id')}\" +\n",
    "#           f\" is {score[0]:.2f} with {score[1]} matched peaks\")\n",
    "\n",
    "# End example --------------\n",
    "\n",
    "# Here I just break it down so you see what is happening behind the scenes\n",
    "# It is basically three function calls (the first two will collect the matching pairs, the third will score them - including normalization)\n",
    "# The time bottleneck is on the last function call (score_best_matches), as it operates on single spectra pairs\n",
    "# Storing the output of matching pairs in some dataframe (tensor) and then scoring them in batches would be much faster\n",
    "# So it is really the last function that needs to be changed\n",
    "# I managed to create a batch version of the first two functions but that did not hold any speedup\n",
    "# Plus it only worked on specific case - multiple spectra in the reference against a single spectrum in the query (not multiple vs multiple)\n",
    "\n",
    "# I am setting the mz_tolerance to 0.1, as this is probably the value we will use by default\n",
    "# That being said, in this exercise it just to cover all potential cases where we can have a peak from one spectrum matching several peaks in the other\n",
    "# Only one (the first) is then selected in the scoring function \n",
    "\n",
    "for spectrum_1 in references:\n",
    "    for spectrum_2 in queries:\n",
    "        spec1 = spectrum_1.peaks.to_numpy\n",
    "        spec2 = spectrum_2.peaks.to_numpy\n",
    "        matching_pairs = collect_peak_pairs(spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "                    shift=0.0, mz_power=0.0,\n",
    "                    intensity_power=1.0)\n",
    "        if matching_pairs is not None:\n",
    "            score = score_best_matches(matching_pairs, spec1, spec2,\n",
    "                                    0.0, 1.0)\n",
    "            print(score)\n",
    "        else: print(\"No matching pairs found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking runtime\n",
    "\n",
    "Below is a small snippets to benchmark runtime of the collect_peak_pairs function and score_best_matches function.\n",
    "To do so we split the approach in two parts, first collecting and storing the matching pairs, second running the score function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to collect matching pairs:  28.9017972946167\n",
      "Time to score matching pairs:  10.086315155029297\n"
     ]
    }
   ],
   "source": [
    "# List to store the matching pairs along with the spectra\n",
    "import time\n",
    "\n",
    "# Very small example\n",
    "references = [spectrum_1, spectrum_3]\n",
    "queries = [spectrum_2, spectrum_4]\n",
    "\n",
    "# Realistic example\n",
    "references = large_references[1000:100000]\n",
    "queries = large_references[0:10]\n",
    "\n",
    "start_collect_peaks = time.time()\n",
    "pairs_to_score_list = []\n",
    "for spectrum_1 in references:\n",
    "    for spectrum_2 in queries:\n",
    "        spec1 = spectrum_1.peaks.to_numpy\n",
    "        spec2 = spectrum_2.peaks.to_numpy\n",
    "        matching_pairs = collect_peak_pairs(spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "                    shift=0.0, mz_power=0.0,\n",
    "                    intensity_power=1.0)\n",
    "        if matching_pairs is not None:\n",
    "            pairs_to_score_list.append([ matching_pairs, spectrum_1, spectrum_2])  \n",
    "end_collect_peaks = time.time()\n",
    "print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)\n",
    "\n",
    "# Now we can score the matching pairs\n",
    "start_score = time.time()\n",
    "for matching_pairs, spectrum_1, spectrum_2 in pairs_to_score_list:\n",
    "    score = score_best_matches(matching_pairs, spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy,\n",
    "                                0.0, 1.0)\n",
    "\n",
    "end_score = time.time()\n",
    "print(\"Time to score matching pairs: \", end_score - start_score)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
