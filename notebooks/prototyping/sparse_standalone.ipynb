{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "if not Path('.git').exists():\n",
    "    %cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import \\\n",
    "    argbatch, mkdir, get_ref_spectra_from_df\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from time import perf_counter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import shared_memory\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "import torch\n",
    "import numba\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "assert cp.cuda.is_available()\n",
    "assert numba.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.similarity.kernels import cosine_greedy_kernel\n",
    "\n",
    "match_limit = 1024\n",
    "max_peaks = 1024\n",
    "batch_size = 2048\n",
    "threshold = .75\n",
    "\n",
    "kernel = compile_cuda_cosine_greedy_kernel(\n",
    "    tolerance=.1,\n",
    "    shift=0,\n",
    "    mz_power=0,\n",
    "    int_power=1,\n",
    "    match_limit=match_limit,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32768/32768 [00:06<00:00, 5195.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from cudams.utils import get_spectra_batches\n",
    "\n",
    "references, queries, batched_inputs = get_spectra_batches(\n",
    "    batch_size=batch_size,\n",
    "    max_peaks=max_peaks,\n",
    "    max_pairs=(batch_size**2) * 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:28<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "! rm -rf data/output\n",
    "! mkdir -p data/output\n",
    "for batch_i in tqdm(range(len(batched_inputs))):\n",
    "    (rspec, rlen, rstart, rend), (qspec, qlen, qstart, qend) = batched_inputs[\n",
    "        batch_i\n",
    "    ]\n",
    "    \n",
    "    lens = cp.zeros((2, batch_size), \"int32\")\n",
    "    lens[0, :len(rlen)] = cp.asarray(rlen)\n",
    "    lens[1, :len(qlen)] = cp.asarray(qlen)\n",
    "    rspec = cp.asarray(rspec)\n",
    "    qspec = cp.asarray(qspec)\n",
    "    out = cp.zeros((3, batch_size, batch_size), dtype=\"float32\")\n",
    "    \n",
    "    kernel(rspec, qspec, lens, out)\n",
    "    \n",
    "    mask = out[0] >= threshold\n",
    "    row, col = cp.nonzero(mask)\n",
    "    score, matches, overflow = out[:, mask]\n",
    "    rabs = rstart + row\n",
    "    qabs = qstart + col\n",
    "    cp.savez_compressed(f'data/output/{rstart}-{rend}-{qstart}-{qend}.npz', \n",
    "                        rabs=rabs, \n",
    "                        qabs=qabs, \n",
    "                        score=score, \n",
    "                        matches=matches,\n",
    "                        overflow=overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,1M\tdata/output\n"
     ]
    }
   ],
   "source": [
    "! du -hs data/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want to query these absolute query IDs, and sort their results\n",
    "\n",
    "query = np.array([1, 42, 121, 100010])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False]\n"
     ]
    }
   ],
   "source": [
    "q = cp.asarray(query)\n",
    "for file in Path('data/output').glob('*.npz'):\n",
    "    bunch = cp.load(file)\n",
    "    qabs = bunch['qabs']\n",
    "    interest = cp.isin(q, qabs)\n",
    "    if interest.any():\n",
    "        # We need to accumulate interests over all batches \n",
    "        # Concat them, sort them by `score` and return\n",
    "        # cp.where(qabs == , )\n",
    "    print(interest)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
