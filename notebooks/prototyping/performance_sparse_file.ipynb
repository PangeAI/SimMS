{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import argbatch, mkdir, get_ref_spectra_from_df\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numba import cuda\n",
    "from itertools import product\n",
    "from time import perf_counter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import shared_memory\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "assert cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "tolerance: float = 0.1\n",
    "shift: float = 0\n",
    "mz_power: float = 0\n",
    "int_power: float = 1\n",
    "\n",
    "## How many pairs per batch. Has to be a power of 2.\n",
    "# Hardware specific - An RTX2070 works best at around 1024 * 2\n",
    "# But Colab T4 GPU might work best at 1024 * 4\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "# MAX NUMBER OF PEAKS during filtering. Due to nature of matrices, having large number of \n",
    "# peaks will increase memory requirements. After 1024, this has diminishing benefits, as \n",
    "# smaller and smaller (likely noisy) peaks are taken into consideration when running similarity.\n",
    "MAX_PEAKS = 1024\n",
    "\n",
    "# MATCH_LIMIT specifies max how many mz-mz pairs we could consider for each RQ pair, before we sort and filter. \n",
    "# E.g. a value of 256 usually causes around ~0.003% of RQ pairs to \"overflow\".\n",
    "# The overflown RQ scores will be strictly less than or equal to perfectly accurate score.\n",
    "# The mean absolute difference at 256, for all overflown pairs is on the order of ~1e-3\n",
    "# Small values of MATCH_LIMIT (e.g. 128, 64,) cause a dramatic speedup in the processing speed.\n",
    "MATCH_LIMIT = 1024\n",
    "\n",
    "# Since Greedy cosine is an unstable algorithm, because approximate mz-mz values do not\n",
    "# result in approximately the same scores and number of matches.\n",
    "# So we need to use fp64 to minimize the deviation as much as possible.\n",
    "# Using float32 causes a significant speedup in the processing speed.\n",
    "dtype = 'float32'\n",
    "\n",
    "# Data path\n",
    "reference_csv_file = Path(\"data/input/example_dataset_tornike.csv\")\n",
    "query_csv_file = Path(\"data/input/example_dataset_tornike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [00:05<00:00, 2982.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from cudams.utils import get_spectra_batches\n",
    "\n",
    "len_spectra = 1024\n",
    "references, queries, batches_inputs = get_spectra_batches(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_peaks=MAX_PEAKS,\n",
    "    max_pairs=16 * (BATCH_SIZE ** 2), # 16 batches, give or take...\n",
    "    padding=None,\n",
    ")\n",
    "TOTAL_BATCHES = len(batches_inputs)\n",
    "batch_outputs = np.empty(shape=(TOTAL_BATCHES,4),dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-scalar numpy.ndarray cannot be used for fill",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m (rspec, rlen, rstart, rend), (qspec, qlen, qstart, qend) \u001b[38;5;241m=\u001b[39m batches_inputs[\n\u001b[1;32m     21\u001b[0m     batch_i\n\u001b[1;32m     22\u001b[0m ]\n\u001b[1;32m     24\u001b[0m lens \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m, BATCH_SIZE), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mlens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrlen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m rlen\n\u001b[1;32m     26\u001b[0m lens[\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;28mlen\u001b[39m(qlen)] \u001b[38;5;241m=\u001b[39m qlen\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We order empty space for results on GPU RAM\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# scores = cp.zeros(\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     (BATCH_SIZE, BATCH_SIZE), dtype=\"float32\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     (BATCH_SIZE, BATCH_SIZE), dtype=\"uint8\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1588\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__setitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_indexing.pyx:50\u001b[0m, in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_indexing.pyx:1016\u001b[0m, in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/core.pyx:732\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.fill\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-scalar numpy.ndarray cannot be used for fill"
     ]
    }
   ],
   "source": [
    "from cudams.similarity.kernels import cosine_greedy_kernel\n",
    "\n",
    "kernel = compile_cuda_cosine_greedy_kernel(\n",
    "    tolerance=tolerance,\n",
    "    shift=shift,\n",
    "    mz_power=mz_power,\n",
    "    int_power=int_power,\n",
    "    match_limit=MATCH_LIMIT,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "R, Q = BATCH_SIZE, BATCH_SIZE\n",
    "THREADS_PER_BLOCK = (32, 32)\n",
    "BLOCKS_PER_GRID_X = math.ceil(R / THREADS_PER_BLOCK[0])\n",
    "BLOCKS_PER_GRID_Y = math.ceil(Q / THREADS_PER_BLOCK[1])\n",
    "BLOCKS_PER_GRID = (BLOCKS_PER_GRID_X, BLOCKS_PER_GRID_Y)\n",
    "\n",
    "for batch_i in tqdm(range(TOTAL_BATCHES)):\n",
    "        # We get our batch and lengths (lengths are different for different spectra)\n",
    "    (rspec, rlen, rstart, rend), (qspec, qlen, qstart, qend) = batches_inputs[\n",
    "        batch_i\n",
    "    ]\n",
    "    \n",
    "    lens = cp.zeros((2, BATCH_SIZE), \"int32\")\n",
    "    lens[0, :len(rlen)] = rlen\n",
    "    lens[1, :len(qlen)] = qlen\n",
    "    \n",
    "    \n",
    "    # We order empty space for results on GPU RAM\n",
    "    # scores = cp.zeros(\n",
    "    #     (BATCH_SIZE, BATCH_SIZE), dtype=\"float32\"\n",
    "    # )\n",
    "    # used_matches = cp.zeros(\n",
    "    #     (BATCH_SIZE, BATCH_SIZE), dtype=\"int32\"\n",
    "    # )\n",
    "    # overflow = cp.zeros(\n",
    "    #     (BATCH_SIZE, BATCH_SIZE), dtype=\"uint8\"\n",
    "    # )\n",
    "    out = cp.zeros(\n",
    "        (BATCH_SIZE, BATCH_SIZE, 2), dtype=dtype\n",
    "    )\n",
    "    overflow = cp.zeros(\n",
    "        (BATCH_SIZE, BATCH_SIZE, 1), dtype=\"uint8\"\n",
    "    )\n",
    "\n",
    "    # rmz = cp.asarray(rspec[0])\n",
    "    # rint = cp.asarray(rspec[1])\n",
    "    \n",
    "    # qmz = cp.asarray(qspec[0])\n",
    "    # qint = cp.asarray(qspec[1])\n",
    "    \n",
    "    # rlen = cp.asarray(lens[0])\n",
    "    # qlen = cp.asarray(lens[1])\n",
    "    \n",
    "    # rnorm = ((rmz ** mz_power) * (rint ** int_power)).sum()\n",
    "    \n",
    "    kernel[BLOCKS_PER_GRID, THREADS_PER_BLOCK](\n",
    "            rspec,\n",
    "            qspec,            \n",
    "            lens,\n",
    "            out,\n",
    "            overflow,\n",
    "    )\n",
    "    out.get()\n",
    "    \n",
    "    # break\n",
    "# plt.imshow(scores.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
