{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import argbatch, mkdir\n",
    "from cudams.data import get_ref_spectra_from_df\n",
    "from cudams.kernel import compile\n",
    "from cudams.utils import name2idx\n",
    "from cudams.cosine import similarity\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from cudams.data import spectra_peaks_to_tensor\n",
    "from cudams.processor import Config\n",
    "from numba import cuda\n",
    "from itertools import product\n",
    "from time import perf_counter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import shared_memory\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "assert cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "tolerance: float = 0.1\n",
    "shift: float = 0\n",
    "mz_power: float = 0\n",
    "int_power: float = 1\n",
    "\n",
    "## How many pairs per batch. Has to be a power of 2.\n",
    "# Hardware specific - An RTX2070 works best at around 1024 * 2\n",
    "# But Colab T4 GPU might work best at 1024 * 4\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# MAX NUMBER OF PEAKS \n",
    "MAX_PEAKS = 1024\n",
    "\n",
    "# MATCH_LIMIT specifies max how many mz-mz pairs we could consider for each RQ pair, before we sort and filter. \n",
    "# E.g. a value of 256 usually causes around ~0.003% of RQ pairs to \"overflow\".\n",
    "# The overflown RQ scores will be strictly less than or equal to perfectly accurate score.\n",
    "# The mean absolute difference at 256, for all overflown pairs is on the order of ~1e-3\n",
    "# Small values of MATCH_LIMIT (e.g. 128, 64,) cause a dramatic speedup in the processing speed.\n",
    "MATCH_LIMIT = 1024 * 4\n",
    "\n",
    "## GPU-specific constants\n",
    "THREADS_PER_BLOCK = (32, 32)\n",
    "BLOCKS_PER_GRID_X = math.ceil(BATCH_SIZE / THREADS_PER_BLOCK[0])\n",
    "BLOCKS_PER_GRID_Y = math.ceil(BATCH_SIZE / THREADS_PER_BLOCK[1])\n",
    "BLOCKS_PER_GRID = (BLOCKS_PER_GRID_X, BLOCKS_PER_GRID_Y)\n",
    "\n",
    "# Since Greedy cosine is an unstable algorithm, because approximate mz-mz values do not\n",
    "# result in approximately the same scores and number of matches.\n",
    "# So we need to use fp64 to minimize the deviation as much as possible.\n",
    "# Using float32 causes a significant speedup in the processing speed.\n",
    "dtype = 'float64'\n",
    "\n",
    "# Data path\n",
    "reference_csv_file = Path(\"data/input/test_set_cosine.csv\")\n",
    "query_csv_file = Path(\"data/input/test_set_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 386.19it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 3631.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from cudams.processor import CudaCosineGreedy, CpuCosineGreedy\n",
    "from collections import defaultdict\n",
    "from matchms import calculate_scores\n",
    "from tqdm import tqdm\n",
    "from matchms.filtering import normalize_intensities, select_by_mz, select_by_relative_intensity, reduce_to_number_of_peaks, \\\n",
    "    require_minimum_number_of_peaks\n",
    "from cudams.utils import mute_stdout\n",
    "\n",
    "def process_spectrum(spectrum: np.ndarray) -> np.ndarray:\n",
    "    # spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    # spectrum = normalize_intensities(spectrum)\n",
    "    # spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    # spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=MAX_PEAKS)\n",
    "    # spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "ref_spectra_df_path = Path(reference_csv_file)\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "references = get_ref_spectra_from_df(ref_spectra_df, \n",
    "                                    spectrum_processor=process_spectrum,\n",
    "                                    limit=BATCH_SIZE * 2,)\n",
    "\n",
    "query_spectra_df_path = Path(query_csv_file)\n",
    "query_spectra_df = pd.read_csv(query_spectra_df_path)\n",
    "queries = get_ref_spectra_from_df(query_spectra_df, \n",
    "                                spectrum_processor=process_spectrum,\n",
    "                                limit=BATCH_SIZE * 2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = references[-BATCH_SIZE:]\n",
    "queries = queries[-BATCH_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "Batch all references: 1it [00:00, 89.64it/s]\n",
      "Batch all queries: 1it [00:00, 90.27it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST IMPORTANT ====>  0.9990463256835938 250\n",
      "Overflows 0.0 0\n",
      "CPU orig vs GPU 0.9988288879394531 614\n",
      "CPU opt vs GPU: 0.9993743896484375 328\n",
      "CPU orig vs CPU opt 0.9993362426757812 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    262144.000000\n",
       "mean          0.000076\n",
       "std           0.034719\n",
       "min          -2.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from matchms.typing import SpectrumType\n",
    "from matchms.similarity import CosineGreedy as OriginalCosineGreedy\n",
    "from cudams.processor import CudaCosineGreedy, CpuCosineGreedy\n",
    "from collections import defaultdict\n",
    "from matchms import calculate_scores\n",
    "from tqdm import tqdm\n",
    "from matchms.filtering import normalize_intensities, select_by_mz, select_by_relative_intensity, reduce_to_number_of_peaks, \\\n",
    "    require_minimum_number_of_peaks\n",
    "from cudams.utils import mute_stdout\n",
    "\n",
    "from matchms.typing import SpectrumType\n",
    "from matchms.similarity.BaseSimilarity import BaseSimilarity\n",
    "from matchms.similarity.spectrum_similarity_functions import (collect_peak_pairs,\n",
    "                                            score_best_matches)\n",
    "\n",
    "\n",
    "class CosineGreedy(OriginalCosineGreedy):\n",
    "    def __init__(self, tolerance: float = 0.1, mz_power: float = 0, intensity_power: float = 1):\n",
    "        super().__init__(tolerance, mz_power, intensity_power)\n",
    "        \n",
    "    def pair(self, reference: SpectrumType, query: SpectrumType) -> Tuple[float, int]:\n",
    "        \"\"\"Calculate cosine score between two spectra.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reference\n",
    "            Single reference spectrum.\n",
    "        query\n",
    "            Single query spectrum.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Score\n",
    "            Tuple with cosine score and number of matched peaks.\n",
    "        \"\"\"\n",
    "        def get_matching_pairs():\n",
    "            \"\"\"Get pairs of peaks that match within the given tolerance.\"\"\"\n",
    "            matching_pairs = collect_peak_pairs(spec1, spec2, self.tolerance,\n",
    "                                                shift=0.0, mz_power=self.mz_power,\n",
    "                                                intensity_power=self.intensity_power)\n",
    "            if matching_pairs is None:\n",
    "                return None\n",
    "            # TODO: Original doesn't have kind=stable!\n",
    "            matching_pairs = matching_pairs[np.argsort(matching_pairs[:, 2],kind='stable')[::-1], :]\n",
    "            return matching_pairs\n",
    "\n",
    "        spec1 = reference.peaks.to_numpy\n",
    "        spec2 = query.peaks.to_numpy\n",
    "        matching_pairs = get_matching_pairs()\n",
    "        if matching_pairs is None:\n",
    "            return np.asarray((float(0), 0), dtype=self.score_datatype)\n",
    "        # return np.asarray((float(1), len(matching_pairs)), dtype=self.score_datatype)\n",
    "    \n",
    "        score = score_best_matches(matching_pairs, spec1, spec2,\n",
    "                                   self.mz_power, self.intensity_power)\n",
    "        return np.asarray(score, dtype=self.score_datatype)\n",
    "\n",
    "similarity_measure = CosineGreedy(tolerance=tolerance, \n",
    "                                mz_power= 0.0, \n",
    "                                intensity_power = 1.0)\n",
    "C_orig = calculate_scores(references, queries, similarity_measure, is_symmetric=False)\n",
    "Cy = C_orig.to_array()\n",
    "Cy, Cm = Cy['CosineGreedy_score'], Cy['CosineGreedy_matches']\n",
    "Cy = np.stack([Cy,Cm],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "Batch all references: 1it [00:00, 72.34it/s]\n",
      "Batch all queries: 1it [00:00, 73.91it/s]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST IMPORTANT ====>  1.0 0\n",
      "Overflows 0.0 0\n",
      "CPU orig vs GPU 1.0 0\n",
      "CPU opt vs GPU: 0.9993362426757812 348\n",
      "CPU orig vs CPU opt 0.9993362426757812 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    262144.0\n",
       "mean          0.0\n",
       "std           0.0\n",
       "min           0.0\n",
       "25%           0.0\n",
       "50%           0.0\n",
       "75%           0.0\n",
       "max           0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from matchms.typing import SpectrumType\n",
    "from matchms.similarity.BaseSimilarity import BaseSimilarity\n",
    "from matchms.similarity.spectrum_similarity_functions import (collect_peak_pairs,\n",
    "                                            score_best_matches)\n",
    "\n",
    "from matchms.typing import SpectrumType\n",
    "from matchms.similarity import CosineGreedy as OriginalCosineGreedy\n",
    "from cudams.processor import CudaCosineGreedy, CpuCosineGreedy\n",
    "from collections import defaultdict\n",
    "from matchms import calculate_scores\n",
    "from matchms.similarity import CosineGreedy\n",
    "from tqdm import tqdm\n",
    "from matchms.filtering import normalize_intensities, select_by_mz, select_by_relative_intensity, reduce_to_number_of_peaks, \\\n",
    "    require_minimum_number_of_peaks\n",
    "from cudams.utils import mute_stdout\n",
    "\n",
    "refs = list([r.peaks.to_numpy for r in references])\n",
    "ques = list([q.peaks.to_numpy for q in queries])\n",
    "\n",
    "rlims = argbatch(refs, BATCH_SIZE)\n",
    "qlims = argbatch(ques, BATCH_SIZE)\n",
    "R = len(references)\n",
    "Q = len(queries)\n",
    "\n",
    "batches_rq = list(product(rlims, qlims))\n",
    "\n",
    "for (rstart, rend), (qstart, qend) in tqdm(batches_rq, total=len(batches_rq)):\n",
    "    rspec = refs[rstart:rend]\n",
    "    qspec = ques[qstart:qend]\n",
    "    out_true = np.full((BATCH_SIZE, BATCH_SIZE, 2), fill_value=0, dtype='float32')\n",
    "    for (i, spec1), (j, spec2) in product(enumerate(rspec), enumerate(qspec)):\n",
    "            score = similarity(\n",
    "                spec1,\n",
    "                spec2,\n",
    "                tolerance=tolerance,\n",
    "                shift=shift,\n",
    "                mz_power=mz_power,\n",
    "                int_power=int_power,\n",
    "            )\n",
    "            if score is not None:\n",
    "                out_true[i,j,0] = score[0]\n",
    "                out_true[i,j,1] = score[1]\n",
    "    \n",
    "C = np.empty((BATCH_SIZE,BATCH_SIZE,2), dtype='float32')\n",
    "C[:] = out_true[:]\n",
    "\n",
    "cosine = CudaCosineGreedy(\n",
    "            tolerance=tolerance,\n",
    "            mz_power=0,\n",
    "            intensity_power=1, \n",
    "            shift=0,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            match_limit=MATCH_LIMIT,\n",
    "        )\n",
    "cosine.compile()\n",
    "G, Ov = cosine.matrix(\n",
    "    references=references, \n",
    "    queries=queries, \n",
    "    array_type=\"numpy\"\n",
    ")\n",
    "R,Q,_ = Cy.shape\n",
    "\n",
    "a,b = Cy[:R,:Q, 1], G[:R,:Q, 1]\n",
    "C_match = np.isclose(Cy[:R,:Q, 1], G[:R,:Q, 1])\n",
    "corr = C_match.mean()\n",
    "print(\"MOST IMPORTANT ====> \", corr, (1-C_match).sum())\n",
    "\n",
    "print(\"Overflows\", Ov[:R,:Q].mean(), Ov[:R,:Q].sum())\n",
    "C_match = np.isclose(Cy[:R,:Q], G[:R,:Q])\n",
    "corr = C_match.mean()\n",
    "print(\"CPU orig vs GPU\", corr, (1-C_match).sum())\n",
    "\n",
    "C_match = np.isclose(C[:R,:Q], G[:R,:Q])\n",
    "corr = C_match.mean()\n",
    "print(\"CPU opt vs GPU:\", corr, (1-C_match).sum())\n",
    "\n",
    "C_match = np.isclose(Cy[:R,:Q], C[:R,:Q])\n",
    "corr = C_match.mean()\n",
    "print(\"CPU orig vs CPU opt\", corr, (1-C_match).sum())\n",
    "pd.Series((b - a).ravel()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST IMPORTANT ====>  0.9996243990384616 5\n",
      "Overflows 0.0 0\n",
      "CPU orig vs GPU 0.9996243990384616 10\n",
      "CPU opt vs GPU: 0.9998497596153846 4\n",
      "CPU orig vs CPU opt 0.9997746394230769 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a,b = Cy[:R,:Q, 1], G[:R,:Q, 1]\n",
    "C_match = np.isclose(Cy[:R,:Q, 1], G[:R,:Q, 1])\n",
    "corr = C_match.mean()\n",
    "print(\"MOST IMPORTANT ====> \", corr, (1-C_match).sum())\n",
    "\n",
    "print(\"Overflows\", Ov[:R,:Q].mean(), Ov[:R,:Q].sum())\n",
    "C_match = np.isclose(Cy[:R,:Q], G[:R,:Q])\n",
    "corr = C_match.mean()\n",
    "print(\"CPU orig vs GPU\", corr, (1-C_match).sum())\n",
    "\n",
    "C_match = np.isclose(C[:R,:Q], G[:R,:Q])\n",
    "corr = C_match.mean()\n",
    "print(\"CPU opt vs GPU:\", corr, (1-C_match).sum())\n",
    "\n",
    "C_match = np.isclose(Cy[:R,:Q], C[:R,:Q])\n",
    "corr = C_match.mean()\n",
    "print(\"CPU orig vs CPU opt\", corr, (1-C_match).sum())\n",
    "# pd.Series((b - a).ravel()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_match = np.isclose(Cy[:R,:Q], G[:R,:Q])\n",
    "a,b = np.nonzero(1-C_match[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6, 58, 58, 63]), array([58,  6, 63, 58]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C_match = np.isclose(Cy[:R,:Q], C[:R,:Q])\n",
    "# a,b = np.nonzero(1-C_match[...,0])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 436542.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010010000000306718 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:00<00:00, 207805.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010010000000306718 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [00:00<00:00, 174213.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004694000000029064 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:00<00:00, 324261.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004694000000029064 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    r, q = references[a[i]].peaks.to_numpy[:,0], \\\n",
    "        queries[b[i]].peaks.to_numpy[:,0]\n",
    "    Cy[a[i],b[i]],G[a[i],b[i]]\n",
    "    pairs = []\n",
    "    diffs = []\n",
    "    lowest_idx = 0\n",
    "    for peak1_idx in tqdm(range(len(r))):\n",
    "        mz = r[peak1_idx]\n",
    "        lo = mz - .1\n",
    "        hi = mz + .1\n",
    "        for peak2_idx in range(lowest_idx, len(q)):\n",
    "            mz2 = q[peak2_idx]\n",
    "            diffs.append(abs(mz2 - hi))\n",
    "            diffs.append(abs(mz2 - lo))\n",
    "            diffs.append(abs(hi - mz2))\n",
    "            diffs.append(abs(lo - mz2))\n",
    "            if mz2 > hi:\n",
    "                break\n",
    "            if mz2 < lo:\n",
    "                lowest_idx = peak2_idx + 1\n",
    "            else:\n",
    "                pairs.append([peak1_idx, peak2_idx])\n",
    "    \n",
    "    print(min(diffs), len(pairs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
