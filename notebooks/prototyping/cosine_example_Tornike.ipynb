{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that are needed for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms import Spectrum\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "ref_spectra_df_path = Path(\"example_dataset_tornike.csv\")\n",
    "if ref_spectra_df_path.exists():\n",
    "    ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "else:\n",
    "    ref_spectra_df = get_reference_spectra(0)\n",
    "    ref_spectra_df.to_csv(ref_spectra_df_path, index=False)\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    # Argh, This function is annoyingly slow. Added simple parallelization.\n",
    "    \n",
    "    # for index, row in spectra_df.iterrows():\n",
    "    def fn(index, row):\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                'precursor_mz': precursor_mz, \n",
    "                                'smiles': smiles, \n",
    "                                'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        return sp\n",
    "    \n",
    "    spectra = Parallel(-2)(delayed(fn)(index, row) for index, row in tqdm(spectra_df.iterrows(), total=len(spectra_df)))\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    return spectra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pbid</th>\n",
       "      <th>pb_smiles</th>\n",
       "      <th>pb_inchikey</th>\n",
       "      <th>precursor_mz</th>\n",
       "      <th>compound_name</th>\n",
       "      <th>peaks_mz</th>\n",
       "      <th>peaks_intensities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499410</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[118.0654, 125.0155, 132.0811, 133.0844, 143.5...</td>\n",
       "      <td>[8.39, 29.17, 66.23, 1.9, 2.4, 999.0, 2.7, 1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499411</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[118.0654, 125.0155, 126.0188, 132.081, 133.08...</td>\n",
       "      <td>[8.29, 54.65, 1.3, 59.94, 1.7, 3.1, 999.0, 3.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>499412</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[117.0701, 118.0654, 125.0155, 126.0188, 132.0...</td>\n",
       "      <td>[1.8, 7.99, 145.75, 3.0, 53.15, 1.4, 1.6, 3.5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499413</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[117.0701, 118.0654, 125.0155, 126.0188, 132.0...</td>\n",
       "      <td>[9.39, 8.19, 289.41, 6.69, 49.35, 1.1, 5.39, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499414</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[91.0544, 115.0545, 117.0576, 117.0702, 118.06...</td>\n",
       "      <td>[1.5, 4.4, 3.3, 41.56, 9.19, 1.2, 1.6, 422.98,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1094297</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 51.023, 51.0249, 52.0263, 53.0387, 5...</td>\n",
       "      <td>[24.28, 375.52, 3.9, 10.89, 17.88, 18.08, 6.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1094298</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 51.023, 52.0264, 53.0386, 59.0241, 6...</td>\n",
       "      <td>[75.22, 934.36, 27.37, 15.88, 15.98, 18.98, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1094299</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 51.023, 52.0264, 52.0307, 53.0385, 5...</td>\n",
       "      <td>[113.59, 999.0, 29.17, 2.4, 8.09, 7.39, 1.7, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1094300</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 50.0164, 51.023, 52.0181, 52.0264, 5...</td>\n",
       "      <td>[191.51, 4.5, 999.0, 1.8, 30.47, 5.0, 2.2, 1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>1094301</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[69.9923, 77.0386, 87.0189, 91.0541, 92.0494, ...</td>\n",
       "      <td>[1.0, 15.78, 9.09, 6.19, 4.4, 24.98, 348.85, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100001 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pbid                        pb_smiles                  pb_inchikey  \\\n",
       "0        499410   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "1        499411   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "2        499412   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "3        499413   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "4        499414   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "...         ...                              ...                          ...   \n",
       "99996   1094297  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "99997   1094298  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "99998   1094299  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "99999   1094300  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "100000  1094301  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "\n",
       "        precursor_mz                                   compound_name  \\\n",
       "0           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "1           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "2           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "3           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "4           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "...              ...                                             ...   \n",
       "99996       190.0611                            5-Phenyl-6-azauracil   \n",
       "99997       190.0611                            5-Phenyl-6-azauracil   \n",
       "99998       190.0611                            5-Phenyl-6-azauracil   \n",
       "99999       190.0611                            5-Phenyl-6-azauracil   \n",
       "100000      190.0611                            5-Phenyl-6-azauracil   \n",
       "\n",
       "                                                 peaks_mz  \\\n",
       "0       [118.0654, 125.0155, 132.0811, 133.0844, 143.5...   \n",
       "1       [118.0654, 125.0155, 126.0188, 132.081, 133.08...   \n",
       "2       [117.0701, 118.0654, 125.0155, 126.0188, 132.0...   \n",
       "3       [117.0701, 118.0654, 125.0155, 126.0188, 132.0...   \n",
       "4       [91.0544, 115.0545, 117.0576, 117.0702, 118.06...   \n",
       "...                                                   ...   \n",
       "99996   [50.0152, 51.023, 51.0249, 52.0263, 53.0387, 5...   \n",
       "99997   [50.0152, 51.023, 52.0264, 53.0386, 59.0241, 6...   \n",
       "99998   [50.0152, 51.023, 52.0264, 52.0307, 53.0385, 5...   \n",
       "99999   [50.0152, 50.0164, 51.023, 52.0181, 52.0264, 5...   \n",
       "100000  [69.9923, 77.0386, 87.0189, 91.0541, 92.0494, ...   \n",
       "\n",
       "                                        peaks_intensities  \n",
       "0       [8.39, 29.17, 66.23, 1.9, 2.4, 999.0, 2.7, 1.1...  \n",
       "1       [8.29, 54.65, 1.3, 59.94, 1.7, 3.1, 999.0, 3.2...  \n",
       "2       [1.8, 7.99, 145.75, 3.0, 53.15, 1.4, 1.6, 3.5,...  \n",
       "3       [9.39, 8.19, 289.41, 6.69, 49.35, 1.1, 5.39, 3...  \n",
       "4       [1.5, 4.4, 3.3, 41.56, 9.19, 1.2, 1.6, 422.98,...  \n",
       "...                                                   ...  \n",
       "99996   [24.28, 375.52, 3.9, 10.89, 17.88, 18.08, 6.29...  \n",
       "99997   [75.22, 934.36, 27.37, 15.88, 15.98, 18.98, 16...  \n",
       "99998   [113.59, 999.0, 29.17, 2.4, 8.09, 7.39, 1.7, 2...  \n",
       "99999   [191.51, 4.5, 999.0, 1.8, 30.47, 5.0, 2.2, 1.6...  \n",
       "100000  [1.0, 15.78, 9.09, 6.19, 4.4, 24.98, 348.85, 5...  \n",
       "\n",
       "[100001 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_spectra_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the \"most\" time consuming part of the code. \n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def score_best_matches(matching_pairs: np.ndarray, spec1: np.ndarray,\n",
    "                       spec2: np.ndarray, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0) -> Tuple[float, int]:\n",
    "    \"\"\"Calculate cosine-like score by multiplying matches. Does require a sorted\n",
    "    list of matching peaks (sorted by intensity product).\"\"\"\n",
    "    score = float(0.0)\n",
    "    used_matches = int(0)\n",
    "    used1 = set()\n",
    "    used2 = set()\n",
    "    for i in range(matching_pairs.shape[0]):\n",
    "        if not matching_pairs[i, 0] in used1 and not matching_pairs[i, 1] in used2:\n",
    "            score += matching_pairs[i, 2]\n",
    "            used1.add(matching_pairs[i, 0])  # Every peak can only be paired once\n",
    "            used2.add(matching_pairs[i, 1])  # Every peak can only be paired once\n",
    "            used_matches += 1\n",
    "\n",
    "    # Normalize score:\n",
    "    spec1_power = spec1[:, 0] ** mz_power * spec1[:, 1] ** intensity_power\n",
    "    spec2_power = spec2[:, 0] ** mz_power * spec2[:, 1] ** intensity_power\n",
    "\n",
    "\n",
    "    score = score/(np.sum(spec1_power ** 2) ** 0.5 * np.sum(spec2_power ** 2) ** 0.5)\n",
    "    return score, used_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use case\n",
    "\n",
    "Here I am intentionally creating different use case that we might encounter in prod:\n",
    "\n",
    "    - Spectra of different lengths\n",
    "\n",
    "    - Spectra containing several very close m/z which will fall within the tolerance window (spectrum 4 mz:100 and mz:100.001)\n",
    "    \n",
    "    - This is not covered here but we could also have different number of spectra in references and queries - This will always happen in prod actually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 18:15:13,114:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-12 18:15:13,116:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-12 18:15:13,116:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-12 18:15:13,117:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n"
     ]
    }
   ],
   "source": [
    "spectrum_1 = Spectrum(mz=np.array([100, 150, 200., 203, 234]),\n",
    "                      intensities=np.array([0.7, 0.2, 0.1, 0.1, 0.1]),\n",
    "                      metadata={'id': 'spectrum1'})\n",
    "spectrum_2 = Spectrum(mz=np.array([100, 140, 190., 210]),\n",
    "                      intensities=np.array([0.4, 0.2, 0.1, 0.1]),\n",
    "                      metadata={'id': 'spectrum2'})\n",
    "spectrum_3 = Spectrum(mz=np.array([110, 140, 195.]),\n",
    "                      intensities=np.array([0.6, 0.2, 0.1]),\n",
    "                      metadata={'id': 'spectrum3'})\n",
    "spectrum_4 = Spectrum(mz=np.array([100, 100.001, 150, 200.]),\n",
    "                      intensities=np.array([0.6, 0.1, 0.3, 0.6]),\n",
    "                      metadata={'id': 'spectrum4'})\n",
    "references = [spectrum_1, spectrum_3]\n",
    "queries = [spectrum_2, spectrum_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100001/100001 [00:25<00:00, 3937.17it/s]\n"
     ]
    }
   ],
   "source": [
    "large_references = get_ref_spectra_from_df(ref_spectra_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7977240352174655, 1)\n",
      "(0.7968798037362897, 3)\n",
      "(0.13318543164240537, 1)\n",
      "No matching pairs found\n"
     ]
    }
   ],
   "source": [
    "# In the matchms library, the cosineGreedy function and Score object would take care of the this for loop\n",
    "# There may be some extra data prep and filter as well but we can ignore that for now\n",
    "# and reorganise the data to return it as one single output.\n",
    "# Here is an example of how it would work by default:\n",
    "\n",
    "# Start example ------------\n",
    "\n",
    "# import numpy as np\n",
    "# from matchms.similarity import CosineGreedy\n",
    "# from matchms import calculate_scores\n",
    "\n",
    "# similarity_measure = CosineGreedy()\n",
    "# scores = calculate_scores(references, queries, similarity_measure)\n",
    "\n",
    "# This only for printing the results\n",
    "# for (reference, query, score) in scores:\n",
    "#     print(f\"Cosine score between {reference.get('id')} and {query.get('id')}\" +\n",
    "#           f\" is {score[0]:.2f} with {score[1]} matched peaks\")\n",
    "\n",
    "# End example --------------\n",
    "\n",
    "# Here I just break it down so you see what is happening behind the scenes\n",
    "# It is basically three function calls (the first two will collect the matching pairs, the third will score them - including normalization)\n",
    "# The time bottleneck is on the last function call (score_best_matches), as it operates on single spectra pairs\n",
    "# Storing the output of matching pairs in some dataframe (tensor) and then scoring them in batches would be much faster\n",
    "# So it is really the last function that needs to be changed\n",
    "# I managed to create a batch version of the first two functions but that did not hold any speedup\n",
    "# Plus it only worked on specific case - multiple spectra in the reference against a single spectrum in the query (not multiple vs multiple)\n",
    "\n",
    "# I am setting the mz_tolerance to 0.1, as this is probably the value we will use by default\n",
    "# That being said, in this exercise it just to cover all potential cases where we can have a peak from one spectrum matching several peaks in the other\n",
    "# Only one (the first) is then selected in the scoring function \n",
    "\n",
    "for spectrum_1 in references:\n",
    "    for spectrum_2 in queries:\n",
    "        spec1 = spectrum_1.peaks.to_numpy\n",
    "        spec2 = spectrum_2.peaks.to_numpy\n",
    "        matching_pairs = collect_peak_pairs(spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "                    shift=0.0, mz_power=0.0,\n",
    "                    intensity_power=1.0)\n",
    "        if matching_pairs is not None:\n",
    "            score = score_best_matches(matching_pairs, spec1, spec2,\n",
    "                                    0.0, 1.0)\n",
    "            print(score)\n",
    "        else: print(\"No matching pairs found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking runtime\n",
    "\n",
    "Below is a small snippets to benchmark runtime of the collect_peak_pairs function and score_best_matches function.\n",
    "To do so we split the approach in two parts, first collecting and storing the matching pairs, second running the score function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 21:58:57.073761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-12 21:58:57.073893: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2014/91698 [01:04<48:03, 31.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m spec1 \u001b[39m=\u001b[39m spectrum_1\u001b[39m.\u001b[39mpeaks\u001b[39m.\u001b[39mto_numpy\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m spec2 \u001b[39m=\u001b[39m spectrum_2\u001b[39m.\u001b[39mpeaks\u001b[39m.\u001b[39mto_numpy\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m matching_pairs \u001b[39m=\u001b[39m collect_peak_pairs(spectrum_1\u001b[39m.\u001b[39;49mpeaks\u001b[39m.\u001b[39;49mto_numpy, spectrum_2\u001b[39m.\u001b[39;49mpeaks\u001b[39m.\u001b[39;49mto_numpy, \u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m             shift\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, mz_power\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m             intensity_power\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m matching_pairs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m     pairs_to_score_list\u001b[39m.\u001b[39mappend([ matching_pairs, spectrum_1, spectrum_2])  \n",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollect_peak_pairs\u001b[39m(spec1: np\u001b[39m.\u001b[39mndarray, spec2: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                        tolerance: \u001b[39mfloat\u001b[39m, shift: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, mz_power: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                        intensity_power: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# pylint: disable=too-many-arguments\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m\"\"\"Find matching pairs between two spectra.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m    Args\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m        Array of found matching peaks.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     matches \u001b[39m=\u001b[39m find_matches(spec1[:, \u001b[39m0\u001b[39;49m], spec2[:, \u001b[39m0\u001b[39;49m], tolerance, shift)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     idx1 \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m matches]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     idx2 \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m matches]\n",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m a \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(a)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m b \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(b)[\u001b[39mNone\u001b[39;00m,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m a \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mrepeat(a, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, repeats\u001b[39m=\u001b[39;49mb\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m b \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrepeat(b, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, repeats\u001b[39m=\u001b[39ma\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#X35sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m c \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mwhere(tf\u001b[39m.\u001b[39mabs(a \u001b[39m-\u001b[39m b) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tolerance)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:7002\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(input, repeats, axis, name)\u001b[0m\n\u001b[1;32m   7000\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m reshape(\u001b[39minput\u001b[39m, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m   7001\u001b[0m   axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 7002\u001b[0m \u001b[39mreturn\u001b[39;00m repeat_with_axis(\u001b[39minput\u001b[39;49m, repeats, axis, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:6839\u001b[0m, in \u001b[0;36mrepeat_with_axis\u001b[0;34m(data, repeats, axis, name)\u001b[0m\n\u001b[1;32m   6837\u001b[0m \u001b[39m# If we know that `repeats` is a scalar, then we can just tile & reshape.\u001b[39;00m\n\u001b[1;32m   6838\u001b[0m \u001b[39mif\u001b[39;00m repeats\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mnum_elements() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 6839\u001b[0m   repeats \u001b[39m=\u001b[39m reshape(repeats, [])\n\u001b[1;32m   6840\u001b[0m   expanded \u001b[39m=\u001b[39m expand_dims(data, axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m   6841\u001b[0m   tiled \u001b[39m=\u001b[39m tile_one_dimension(expanded, axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, repeats)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:196\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     61\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m     63\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[1;32m    197\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[1;32m    198\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:8570\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8568\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   8569\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 8570\u001b[0m   \u001b[39mreturn\u001b[39;00m reshape_eager_fallback(\n\u001b[1;32m   8571\u001b[0m       tensor, shape, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m   8572\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m   8573\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:8592\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8590\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape_eager_fallback\u001b[39m(tensor, shape, name, ctx):\n\u001b[1;32m   8591\u001b[0m   _attr_T, (tensor,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39margs_to_matching_eager([tensor], ctx, [])\n\u001b[0;32m-> 8592\u001b[0m   _attr_Tshape, (shape,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([shape], ctx, [_dtypes\u001b[39m.\u001b[39;49mint32, _dtypes\u001b[39m.\u001b[39;49mint64, ], _dtypes\u001b[39m.\u001b[39;49mint32)\n\u001b[1;32m   8593\u001b[0m   _inputs_flat \u001b[39m=\u001b[39m [tensor, shape]\n\u001b[1;32m   8594\u001b[0m   _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mTshape\u001b[39m\u001b[39m\"\u001b[39m, _attr_Tshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:262\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    259\u001b[0m     tensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m   tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[1;32m    263\u001b[0m       t, dtype, preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype, ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    265\u001b[0m ret\u001b[39m.\u001b[39mappend(tensor)\n\u001b[1;32m    266\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1625\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m preferred_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1624\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1625\u001b[0m     ret \u001b[39m=\u001b[39m conversion_func(\n\u001b[1;32m   1626\u001b[0m         value, dtype\u001b[39m=\u001b[39;49mpreferred_dtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1627\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1628\u001b[0m     \u001b[39m# Could not coerce the conversion to use the preferred dtype.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1596\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_autopacking_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1595\u001b[0m   \u001b[39m\"\"\"Tensor conversion function that automatically packs arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1596\u001b[0m   \u001b[39mif\u001b[39;00m as_ref \u001b[39mor\u001b[39;00m _should_not_autopack(v):\n\u001b[1;32m   1597\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m   1598\u001b[0m   inferred_dtype \u001b[39m=\u001b[39m _get_dtype_from_nested_lists(v)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1590\u001b[0m, in \u001b[0;36m_should_not_autopack\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_should_not_autopack\u001b[39m(v):\n\u001b[1;32m   1585\u001b[0m   \u001b[39m# The condition we really want is\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m   \u001b[39m#    any(isinstance(elem, core.Tensor))\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m   \u001b[39m# but it is >5x slower due to abc.ABCMeta.__instancecheck__.\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m   \u001b[39m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m   \u001b[39m# TODO(slebedev): add nest.all?\u001b[39;00m\n\u001b[0;32m-> 1590\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39;49m(\u001b[39mtype\u001b[39;49m(elem) \u001b[39min\u001b[39;49;00m _NON_AUTOPACKABLE_TYPES \u001b[39mfor\u001b[39;49;00m elem \u001b[39min\u001b[39;49;00m nest\u001b[39m.\u001b[39;49mflatten(v))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List to store the matching pairs along with the spectra\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "# Very small example\n",
    "references = [spectrum_1, spectrum_3]\n",
    "queries = [spectrum_2, spectrum_4]\n",
    "\n",
    "# Realistic example\n",
    "references = large_references[1000:100000]\n",
    "queries = large_references[0:10]\n",
    "\n",
    "start_collect_peaks = time.time()\n",
    "pairs_to_score_list = []\n",
    "\n",
    "# def fn(spectrum_1, spectrum_2):\n",
    "#     s1, s2 = spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy\n",
    "#     matching_pairs = collect_peak_pairs(s1, s2, 0.1,\n",
    "#                 shift=0.0, mz_power=0.0,\n",
    "#                 intensity_power=1.0)\n",
    "#     if matching_pairs is not None:\n",
    "#         score = score_best_matches(matching_pairs, s1, s2, 0.0, 1.0)\n",
    "#         if score is not None:\n",
    "#             return [matching_pairs, spectrum_1, spectrum_2, score]\n",
    "# pairs_to_score_list = Parallel(-1)(delayed(fn)(spectrum_1, spectrum_2) \n",
    "#                                    for spectrum_1, spectrum_2 in tqdm(product(references, queries), total=len(references) * len(queries)))\n",
    "# pairs_to_score_list = [e for e in pairs_to_score_list if e is not None] # Make sure if matching_pairs is missing, remove entry\n",
    "\n",
    "# @numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "# @numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # lowest_idx = 0\n",
    "    # matches = []\n",
    "    # for peak1_idx in range(spec1_mz.shape[0]):\n",
    "    #     mz = spec1_mz[peak1_idx]\n",
    "    #     low_bound = mz - tolerance\n",
    "    #     high_bound = mz + tolerance\n",
    "    #     for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "    #         mz2 = spec2_mz[peak2_idx] + shift\n",
    "    #         if mz2 > high_bound:\n",
    "    #             break\n",
    "    #         if mz2 < low_bound:\n",
    "    #             lowest_idx = peak2_idx\n",
    "    #         else:\n",
    "    #             matches.append((peak1_idx, peak2_idx))\n",
    "    \n",
    "    a = spectrum_1.peaks.to_numpy[:,0]\n",
    "    b = spectrum_2.peaks.to_numpy[:,0]\n",
    "    a = tf.constant(a)[...,None]\n",
    "    b = tf.constant(b)[None,...]\n",
    "    a = tf.repeat(a, axis=1, repeats=b.shape[1])\n",
    "    b = tf.repeat(b, axis=0, repeats=a.shape[0])\n",
    "    c = tf.where(tf.abs(a - b) <= tolerance)\n",
    "    matches = c.numpy()\n",
    "    return matches\n",
    "\n",
    "for spectrum_1 in tqdm(references):\n",
    "    for spectrum_2 in queries:\n",
    "        spec1 = spectrum_1.peaks.to_numpy\n",
    "        spec2 = spectrum_2.peaks.to_numpy\n",
    "        matching_pairs = collect_peak_pairs(spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "                    shift=0.0, mz_power=0.0,\n",
    "                    intensity_power=1.0)\n",
    "        if matching_pairs is not None:\n",
    "            pairs_to_score_list.append([ matching_pairs, spectrum_1, spectrum_2])  \n",
    "end_collect_peaks = time.time()\n",
    "print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 2), dtype=int64, numpy=\n",
       "array([[11,  1],\n",
       "       [18,  3],\n",
       "       [19,  4],\n",
       "       [21,  5],\n",
       "       [28,  6],\n",
       "       [29,  7],\n",
       "       [29,  8],\n",
       "       [30,  7],\n",
       "       [30,  8],\n",
       "       [42,  9],\n",
       "       [64, 11],\n",
       "       [65, 11],\n",
       "       [66, 12],\n",
       "       [67, 12]])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tolerance = 0.1\n",
    "# a = spectrum_1.peaks.to_numpy[:,0]\n",
    "# b = spectrum_2.peaks.to_numpy[:,0]\n",
    "# a = tf.constant(a)[None,...]\n",
    "# b = tf.constant(b)[...,None]\n",
    "# a = tf.repeat(a, axis=0, repeats=b.shape[0])\n",
    "# b = tf.repeat(b, axis=1, repeats=a.shape[1])\n",
    "# c = tf.where(tf.abs(a - b) <= tolerance)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] ndims must be == 2: 1 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(a)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m b \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(b)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#Y100sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a \u001b[39m@\u001b[39;49m b\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] ndims must be == 2: 1 [Op:MatMul]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can score the matching pairs\n",
    "start_score = time.time()\n",
    "# def fn(matching_pairs, spectrum_1, spectrum_2):\n",
    "#     score = score_best_matches(matching_pairs, spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy,\n",
    "#                                 0.0, 1.0)\n",
    "#     return score\n",
    "\n",
    "# scores = Parallel(-1)(delayed(fn)(matching_pairs, spectrum_1, spectrum_2) \n",
    "#                       for matching_pairs, spectrum_1, spectrum_2 in tqdm(pairs_to_score_list, total=len(pairs_to_score_list)))\n",
    "scores = []\n",
    "for matching_pairs, spectrum_1, spectrum_2 in tqdm(pairs_to_score_list):\n",
    "    scores.append(score_best_matches(matching_pairs, spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy,\n",
    "                                0.0, 1.0))\n",
    "\n",
    "end_score = time.time()\n",
    "print(\"Time to score matching pairs: \", end_score - start_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(pairs_to_score_list, Path('pairs_to_score_list.pickle').open('wb'))\n",
    "# pickle.dump(scores, Path('scores.pickle').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ld = pickle.load(Path('scores.pickle').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(scores_ld) == np.array(scores)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized\n",
    "``` \n",
    "100%|██████████| 91698/91698 [00:56<00:00, 1627.05it/s]\n",
    "Time to collect matching pairs:  56.94396376609802\n",
    "100%|██████████| 635365/635365 [00:21<00:00, 29557.14it/s]\n",
    "Time to score matching pairs:  21.498287439346313\n",
    "```\n",
    "\n",
    "Optimized (CPU parallelism, 12 CPUs)\n",
    "``` \n",
    "100%|██████████| 916980/916980 [00:20<00:00, 44429.67it/s]\n",
    "Time to collect matching pairs:  21.796888828277588\n",
    "100%|██████████| 635365/635365 [00:20<00:00, 30734.33it/s]\n",
    "Time to score matching pairs:  21.340625762939453\n",
    "```\n",
    "\n",
    "Optimized (CPU parallelism 12 CPUs)\n",
    "```\n",
    "100%|██████████| 916980/916980 [00:30<00:00, 29640.48it/s]\n",
    "Time to collect matching pairs:  31.654369831085205\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
