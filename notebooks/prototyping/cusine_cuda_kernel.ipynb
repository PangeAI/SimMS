{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions that are needed for the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms import Spectrum\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_spectra_df_path = Path(\"example_dataset_tornike.csv\")\n",
    "if ref_spectra_df_path.exists():\n",
    "    ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "else:\n",
    "    ref_spectra_df = get_reference_spectra(0)\n",
    "    ref_spectra_df.to_csv(ref_spectra_df_path, index=False)\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    # Argh, This function is annoyingly slow. Added simple parallelization.\n",
    "    \n",
    "    # for index, row in spectra_df.iterrows():\n",
    "    def fn(index, row):\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                'precursor_mz': precursor_mz, \n",
    "                                'smiles': smiles, \n",
    "                                'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        return sp\n",
    "    \n",
    "    spectra = Parallel(-2)(delayed(fn)(index, row) for index, row in tqdm(spectra_df.iterrows(), total=len(spectra_df)))\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pbid</th>\n",
       "      <th>pb_smiles</th>\n",
       "      <th>pb_inchikey</th>\n",
       "      <th>precursor_mz</th>\n",
       "      <th>compound_name</th>\n",
       "      <th>peaks_mz</th>\n",
       "      <th>peaks_intensities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499410</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[118.0654, 125.0155, 132.0811, 133.0844, 143.5...</td>\n",
       "      <td>[8.39, 29.17, 66.23, 1.9, 2.4, 999.0, 2.7, 1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499411</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[118.0654, 125.0155, 126.0188, 132.081, 133.08...</td>\n",
       "      <td>[8.29, 54.65, 1.3, 59.94, 1.7, 3.1, 999.0, 3.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>499412</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[117.0701, 118.0654, 125.0155, 126.0188, 132.0...</td>\n",
       "      <td>[1.8, 7.99, 145.75, 3.0, 53.15, 1.4, 1.6, 3.5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499413</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[117.0701, 118.0654, 125.0155, 126.0188, 132.0...</td>\n",
       "      <td>[9.39, 8.19, 289.41, 6.69, 49.35, 1.1, 5.39, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>499414</td>\n",
       "      <td>Clc1ccccc1CNCCc1c[nH]c2ccccc12</td>\n",
       "      <td>ZSEPJTGBFYRCMJ-UHFFFAOYSA-N</td>\n",
       "      <td>285.1153</td>\n",
       "      <td>N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine</td>\n",
       "      <td>[91.0544, 115.0545, 117.0576, 117.0702, 118.06...</td>\n",
       "      <td>[1.5, 4.4, 3.3, 41.56, 9.19, 1.2, 1.6, 422.98,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1094297</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 51.023, 51.0249, 52.0263, 53.0387, 5...</td>\n",
       "      <td>[24.28, 375.52, 3.9, 10.89, 17.88, 18.08, 6.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1094298</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 51.023, 52.0264, 53.0386, 59.0241, 6...</td>\n",
       "      <td>[75.22, 934.36, 27.37, 15.88, 15.98, 18.98, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1094299</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 51.023, 52.0264, 52.0307, 53.0385, 5...</td>\n",
       "      <td>[113.59, 999.0, 29.17, 2.4, 8.09, 7.39, 1.7, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1094300</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[50.0152, 50.0164, 51.023, 52.0181, 52.0264, 5...</td>\n",
       "      <td>[191.51, 4.5, 999.0, 1.8, 30.47, 5.0, 2.2, 1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>1094301</td>\n",
       "      <td>O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1</td>\n",
       "      <td>QDVLVVJHFWNNJK-UHFFFAOYSA-N</td>\n",
       "      <td>190.0611</td>\n",
       "      <td>5-Phenyl-6-azauracil</td>\n",
       "      <td>[69.9923, 77.0386, 87.0189, 91.0541, 92.0494, ...</td>\n",
       "      <td>[1.0, 15.78, 9.09, 6.19, 4.4, 24.98, 348.85, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100001 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pbid                        pb_smiles                  pb_inchikey  \\\n",
       "0        499410   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "1        499411   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "2        499412   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "3        499413   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "4        499414   Clc1ccccc1CNCCc1c[nH]c2ccccc12  ZSEPJTGBFYRCMJ-UHFFFAOYSA-N   \n",
       "...         ...                              ...                          ...   \n",
       "99996   1094297  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "99997   1094298  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "99998   1094299  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "99999   1094300  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "100000  1094301  O=c1[nH]nc(-c2ccccc2)c(=O)[nH]1  QDVLVVJHFWNNJK-UHFFFAOYSA-N   \n",
       "\n",
       "        precursor_mz                                   compound_name  \\\n",
       "0           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "1           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "2           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "3           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "4           285.1153  N-(2-Chlorobenzyl)-2-(1H-indol-3-yl)ethanamine   \n",
       "...              ...                                             ...   \n",
       "99996       190.0611                            5-Phenyl-6-azauracil   \n",
       "99997       190.0611                            5-Phenyl-6-azauracil   \n",
       "99998       190.0611                            5-Phenyl-6-azauracil   \n",
       "99999       190.0611                            5-Phenyl-6-azauracil   \n",
       "100000      190.0611                            5-Phenyl-6-azauracil   \n",
       "\n",
       "                                                 peaks_mz  \\\n",
       "0       [118.0654, 125.0155, 132.0811, 133.0844, 143.5...   \n",
       "1       [118.0654, 125.0155, 126.0188, 132.081, 133.08...   \n",
       "2       [117.0701, 118.0654, 125.0155, 126.0188, 132.0...   \n",
       "3       [117.0701, 118.0654, 125.0155, 126.0188, 132.0...   \n",
       "4       [91.0544, 115.0545, 117.0576, 117.0702, 118.06...   \n",
       "...                                                   ...   \n",
       "99996   [50.0152, 51.023, 51.0249, 52.0263, 53.0387, 5...   \n",
       "99997   [50.0152, 51.023, 52.0264, 53.0386, 59.0241, 6...   \n",
       "99998   [50.0152, 51.023, 52.0264, 52.0307, 53.0385, 5...   \n",
       "99999   [50.0152, 50.0164, 51.023, 52.0181, 52.0264, 5...   \n",
       "100000  [69.9923, 77.0386, 87.0189, 91.0541, 92.0494, ...   \n",
       "\n",
       "                                        peaks_intensities  \n",
       "0       [8.39, 29.17, 66.23, 1.9, 2.4, 999.0, 2.7, 1.1...  \n",
       "1       [8.29, 54.65, 1.3, 59.94, 1.7, 3.1, 999.0, 3.2...  \n",
       "2       [1.8, 7.99, 145.75, 3.0, 53.15, 1.4, 1.6, 3.5,...  \n",
       "3       [9.39, 8.19, 289.41, 6.69, 49.35, 1.1, 5.39, 3...  \n",
       "4       [1.5, 4.4, 3.3, 41.56, 9.19, 1.2, 1.6, 422.98,...  \n",
       "...                                                   ...  \n",
       "99996   [24.28, 375.52, 3.9, 10.89, 17.88, 18.08, 6.29...  \n",
       "99997   [75.22, 934.36, 27.37, 15.88, 15.98, 18.98, 16...  \n",
       "99998   [113.59, 999.0, 29.17, 2.4, 8.09, 7.39, 1.7, 2...  \n",
       "99999   [191.51, 4.5, 999.0, 1.8, 30.47, 5.0, 2.2, 1.6...  \n",
       "100000  [1.0, 15.78, 9.09, 6.19, 4.4, 24.98, 348.85, 5...  \n",
       "\n",
       "[100001 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_spectra_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the \"most\" time consuming part of the code. \n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def score_best_matches(matching_pairs: np.ndarray, spec1: np.ndarray,\n",
    "                       spec2: np.ndarray, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0) -> Tuple[float, int]:\n",
    "    \"\"\"Calculate cosine-like score by multiplying matches. Does require a sorted\n",
    "    list of matching peaks (sorted by intensity product).\"\"\"\n",
    "    score = float(0.0)\n",
    "    used_matches = int(0)\n",
    "    used1 = set()\n",
    "    used2 = set()\n",
    "    for i in range(matching_pairs.shape[0]):\n",
    "        if not matching_pairs[i, 0] in used1 and not matching_pairs[i, 1] in used2:\n",
    "            score += matching_pairs[i, 2]\n",
    "            used1.add(matching_pairs[i, 0])  # Every peak can only be paired once\n",
    "            used2.add(matching_pairs[i, 1])  # Every peak can only be paired once\n",
    "            used_matches += 1\n",
    "\n",
    "    # Normalize score:\n",
    "    spec1_power = spec1[:, 0] ** mz_power * spec1[:, 1] ** intensity_power\n",
    "    spec2_power = spec2[:, 0] ** mz_power * spec2[:, 1] ** intensity_power\n",
    "\n",
    "\n",
    "    score = score/(np.sum(spec1_power ** 2) ** 0.5 * np.sum(spec2_power ** 2) ** 0.5)\n",
    "    return score, used_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example use case\n",
    "\n",
    "Here I am intentionally creating different use case that we might encounter in prod:\n",
    "\n",
    "    - Spectra of different lengths\n",
    "\n",
    "    - Spectra containing several very close m/z which will fall within the tolerance window (spectrum 4 mz:100 and mz:100.001)\n",
    "    \n",
    "    - This is not covered here but we could also have different number of spectra in references and queries - This will always happen in prod actually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 19:48:14,159:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-21 19:48:14,160:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-21 19:48:14,161:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n",
      "2023-10-21 19:48:14,161:WARNING:matchms:add_precursor_mz:No precursor_mz found in metadata.\n"
     ]
    }
   ],
   "source": [
    "spectrum_1 = Spectrum(mz=np.array([100, 150, 200., 203, 234]),\n",
    "                      intensities=np.array([0.7, 0.2, 0.1, 0.1, 0.1]),\n",
    "                      metadata={'id': 'spectrum1'})\n",
    "spectrum_2 = Spectrum(mz=np.array([100, 140, 190., 210]),\n",
    "                      intensities=np.array([0.4, 0.2, 0.1, 0.1]),\n",
    "                      metadata={'id': 'spectrum2'})\n",
    "spectrum_3 = Spectrum(mz=np.array([110, 140, 195.]),\n",
    "                      intensities=np.array([0.6, 0.2, 0.1]),\n",
    "                      metadata={'id': 'spectrum3'})\n",
    "spectrum_4 = Spectrum(mz=np.array([100, 100.001, 150, 200.]),\n",
    "                      intensities=np.array([0.6, 0.1, 0.3, 0.6]),\n",
    "                      metadata={'id': 'spectrum4'})\n",
    "references = [spectrum_1, spectrum_3]\n",
    "queries = [spectrum_2, spectrum_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100001/100001 [00:23<00:00, 4342.67it/s]\n"
     ]
    }
   ],
   "source": [
    "large_references = get_ref_spectra_from_df(ref_spectra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "references = large_references[1000:]\n",
    "queries = large_references[0:100]\n",
    "batch_size = 1000\n",
    "\n",
    "s1p = [s.peaks.to_numpy.astype('float32') for s in references]\n",
    "s1p = sorted(s1p, key=len)\n",
    "\n",
    "s2p = [s.peaks.to_numpy.astype('float32') for s in queries]\n",
    "s2p = sorted(s2p, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5, 2)\n",
      "---> (1000, 5, 2)\n",
      "1000 100\n",
      "(1000, 5, 2)\n",
      "---> (1000, 5, 2)\n",
      "1000 100\n",
      "(1000, 5, 2)\n",
      "---> (1000, 5, 2)\n",
      "1000 100\n",
      "(1000, 6, 2)\n",
      "---> (1000, 6, 2)\n",
      "1000 100\n",
      "(1000, 6, 2)\n",
      "---> (1000, 6, 2)\n",
      "1000 100\n",
      "(1000, 6, 2)\n",
      "---> (1000, 6, 2)\n",
      "1000 100\n",
      "(1000, 7, 2)\n",
      "---> (1000, 7, 2)\n",
      "1000 100\n",
      "(1000, 7, 2)\n",
      "---> (1000, 7, 2)\n",
      "1000 100\n",
      "(1000, 7, 2)\n",
      "---> (1000, 7, 2)\n",
      "1000 100\n",
      "(1000, 7, 2)\n",
      "---> (1000, 7, 2)\n",
      "1000 100\n",
      "(1000, 8, 2)\n",
      "---> (1000, 8, 2)\n",
      "1000 100\n",
      "(1000, 8, 2)\n",
      "---> (1000, 8, 2)\n",
      "1000 100\n",
      "(1000, 8, 2)\n",
      "---> (1000, 8, 2)\n",
      "1000 100\n",
      "(1000, 9, 2)\n",
      "---> (1000, 9, 2)\n",
      "1000 100\n",
      "(1000, 9, 2)\n",
      "---> (1000, 9, 2)\n",
      "1000 100\n",
      "(1000, 9, 2)\n",
      "---> (1000, 9, 2)\n",
      "1000 100\n",
      "(1000, 10, 2)\n",
      "---> (1000, 10, 2)\n",
      "1000 100\n",
      "(1000, 10, 2)\n",
      "---> (1000, 10, 2)\n",
      "1000 100\n",
      "(1000, 10, 2)\n",
      "---> (1000, 10, 2)\n",
      "1000 100\n",
      "(1000, 11, 2)\n",
      "---> (1000, 11, 2)\n",
      "1000 100\n",
      "(1000, 11, 2)\n",
      "---> (1000, 11, 2)\n",
      "1000 100\n",
      "(1000, 11, 2)\n",
      "---> (1000, 11, 2)\n",
      "1000 100\n",
      "(1000, 12, 2)\n",
      "---> (1000, 12, 2)\n",
      "1000 100\n",
      "(1000, 12, 2)\n",
      "---> (1000, 12, 2)\n",
      "1000 100\n",
      "(1000, 12, 2)\n",
      "---> (1000, 12, 2)\n",
      "1000 100\n",
      "(1000, 13, 2)\n",
      "---> (1000, 13, 2)\n",
      "1000 100\n",
      "(1000, 13, 2)\n",
      "---> (1000, 13, 2)\n",
      "1000 100\n",
      "(1000, 14, 2)\n",
      "---> (1000, 14, 2)\n",
      "1000 100\n",
      "(1000, 14, 2)\n",
      "---> (1000, 14, 2)\n",
      "1000 100\n",
      "(1000, 14, 2)\n",
      "---> (1000, 14, 2)\n",
      "1000 100\n",
      "(1000, 15, 2)\n",
      "---> (1000, 15, 2)\n",
      "1000 100\n",
      "(1000, 15, 2)\n",
      "---> (1000, 15, 2)\n",
      "1000 100\n",
      "(1000, 16, 2)\n",
      "---> (1000, 16, 2)\n",
      "1000 100\n",
      "(1000, 16, 2)\n",
      "---> (1000, 16, 2)\n",
      "1000 100\n",
      "(1000, 16, 2)\n",
      "---> (1000, 16, 2)\n",
      "1000 100\n",
      "(1000, 17, 2)\n",
      "---> (1000, 17, 2)\n",
      "1000 100\n",
      "(1000, 17, 2)\n",
      "---> (1000, 17, 2)\n",
      "1000 100\n",
      "(1000, 18, 2)\n",
      "---> (1000, 18, 2)\n",
      "1000 100\n",
      "(1000, 18, 2)\n",
      "---> (1000, 18, 2)\n",
      "1000 100\n",
      "(1000, 19, 2)\n",
      "---> (1000, 19, 2)\n",
      "1000 100\n",
      "(1000, 19, 2)\n",
      "---> (1000, 19, 2)\n",
      "1000 100\n",
      "(1000, 20, 2)\n",
      "---> (1000, 20, 2)\n",
      "1000 100\n",
      "(1000, 20, 2)\n",
      "---> (1000, 20, 2)\n",
      "1000 100\n",
      "(1000, 21, 2)\n",
      "---> (1000, 21, 2)\n",
      "1000 100\n",
      "(1000, 22, 2)\n",
      "---> (1000, 22, 2)\n",
      "1000 100\n",
      "(1000, 22, 2)\n",
      "---> (1000, 22, 2)\n",
      "1000 100\n",
      "(1000, 23, 2)\n",
      "---> (1000, 23, 2)\n",
      "1000 100\n",
      "(1000, 24, 2)\n",
      "---> (1000, 24, 2)\n",
      "1000 100\n",
      "(1000, 24, 2)\n",
      "---> (1000, 24, 2)\n",
      "1000 100\n",
      "(1000, 25, 2)\n",
      "---> (1000, 25, 2)\n",
      "1000 100\n",
      "(1000, 26, 2)\n",
      "---> (1000, 26, 2)\n",
      "1000 100\n",
      "(1000, 26, 2)\n",
      "---> (1000, 26, 2)\n",
      "1000 100\n",
      "(1000, 27, 2)\n",
      "---> (1000, 27, 2)\n",
      "1000 100\n",
      "(1000, 28, 2)\n",
      "---> (1000, 28, 2)\n",
      "1000 100\n",
      "(1000, 29, 2)\n",
      "---> (1000, 29, 2)\n",
      "1000 100\n",
      "(1000, 29, 2)\n",
      "---> (1000, 29, 2)\n",
      "1000 100\n",
      "(1000, 30, 2)\n",
      "---> (1000, 30, 2)\n",
      "1000 100\n",
      "(1000, 31, 2)\n",
      "---> (1000, 31, 2)\n",
      "1000 100\n",
      "(1000, 32, 2)\n",
      "---> (1000, 32, 2)\n",
      "1000 100\n",
      "(1000, 33, 2)\n",
      "---> (1000, 33, 2)\n",
      "1000 100\n",
      "(1000, 34, 2)\n",
      "---> (1000, 34, 2)\n",
      "1000 100\n",
      "(1000, 35, 2)\n",
      "---> (1000, 35, 2)\n",
      "1000 100\n",
      "(1000, 36, 2)\n",
      "---> (1000, 36, 2)\n",
      "1000 100\n",
      "(1000, 37, 2)\n",
      "---> (1000, 37, 2)\n",
      "1000 100\n",
      "(1000, 39, 2)\n",
      "---> (1000, 39, 2)\n",
      "1000 100\n",
      "(1000, 40, 2)\n",
      "---> (1000, 40, 2)\n",
      "1000 100\n",
      "(1000, 41, 2)\n",
      "---> (1000, 41, 2)\n",
      "1000 100\n",
      "(1000, 42, 2)\n",
      "---> (1000, 42, 2)\n",
      "1000 100\n",
      "(1000, 44, 2)\n",
      "---> (1000, 44, 2)\n",
      "1000 100\n",
      "(1000, 45, 2)\n",
      "---> (1000, 45, 2)\n",
      "1000 100\n",
      "(1000, 47, 2)\n",
      "---> (1000, 47, 2)\n",
      "1000 100\n",
      "(1000, 48, 2)\n",
      "---> (1000, 48, 2)\n",
      "1000 100\n",
      "(1000, 50, 2)\n",
      "---> (1000, 50, 2)\n",
      "1000 100\n",
      "(1000, 52, 2)\n",
      "---> (1000, 52, 2)\n",
      "1000 100\n",
      "(1000, 54, 2)\n",
      "---> (1000, 54, 2)\n",
      "1000 100\n",
      "(1000, 56, 2)\n",
      "---> (1000, 56, 2)\n",
      "1000 100\n",
      "(1000, 58, 2)\n",
      "---> (1000, 58, 2)\n",
      "1000 100\n",
      "(1000, 60, 2)\n",
      "---> (1000, 60, 2)\n",
      "1000 100\n",
      "(1000, 63, 2)\n",
      "---> (1000, 63, 2)\n",
      "1000 100\n",
      "(1000, 66, 2)\n",
      "---> (1000, 66, 2)\n",
      "1000 100\n",
      "(1000, 69, 2)\n",
      "---> (1000, 69, 2)\n",
      "1000 100\n",
      "(1000, 73, 2)\n",
      "---> (1000, 73, 2)\n",
      "1000 100\n",
      "(1000, 77, 2)\n",
      "---> (1000, 77, 2)\n",
      "1000 100\n",
      "(1000, 82, 2)\n",
      "---> (1000, 82, 2)\n",
      "1000 100\n",
      "(1000, 87, 2)\n",
      "---> (1000, 87, 2)\n",
      "1000 100\n",
      "(1000, 94, 2)\n",
      "---> (1000, 94, 2)\n",
      "1000 100\n",
      "(1000, 101, 2)\n",
      "---> (1000, 101, 2)\n",
      "1000 100\n",
      "(1000, 112, 2)\n",
      "---> (1000, 112, 2)\n",
      "1000 100\n",
      "(1000, 126, 2)\n",
      "---> (1000, 126, 2)\n",
      "1000 100\n",
      "(1000, 148, 2)\n",
      "---> (1000, 148, 2)\n",
      "1000 100\n",
      "(1000, 189, 2)\n",
      "---> (1000, 189, 2)\n",
      "1000 100\n",
      "(698, 496, 2)\n",
      "---> (698, 496, 2)\n",
      "698 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chunks(lst, max_size = 1e9, fill_value=float):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    # for i in range(0, len(lst), n):\n",
    "    i = 0\n",
    "    max_size = np.maximum.accumulate(np.array(len(l) for l in chunk))\n",
    "    while True:\n",
    "        chunk = lst[i:i + n]\n",
    "        batch = np.full((len(chunk), max_size, 2), fill_value=fill_value, dtype='float32')\n",
    "        for i,c in enumerate(chunk):\n",
    "            batch[i, :c.shape[0], :] = c\n",
    "        yield batch\n",
    "        \n",
    "s1p_batched = list(chunks(s1p, n=batch_size, fill_value=1e6))\n",
    "s2p_batched = list(chunks(s2p, n=batch_size, fill_value=-1e6))\n",
    "\n",
    "for s1 in s1p_batched:\n",
    "    for s2 in s2p_batched:\n",
    "        R, N, _ = s1.shape\n",
    "        Q, M, _ = s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # for spectrum_2 in queries:\n",
    "        # spec1 = spectrum_1.peaks.to_numpy\n",
    "        # spec2 = spectrum_2.peaks.to_numpy\n",
    "        # ins1 = spectrum_1.peaks._intensities\n",
    "\n",
    "        # mz2 = spectrum_2.peaks._mz\n",
    "        # ins2 = spectrum_2.peaks._intensities\n",
    "        # matching_pairs = collect_peak_pairs(spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "        #             shift=0.0, mz_power=0.0,\n",
    "        #             intensity_power=1.0)\n",
    "        # if matching_pairs is not None:\n",
    "        #     score = score_best_matches(matching_pairs, spec1, spec2, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the matchms library, the cosineGreedy function and Score object would take care of the this for loop\n",
    "# There may be some extra data prep and filter as well but we can ignore that for now\n",
    "# and reorganise the data to return it as one single output.\n",
    "# Here is an example of how it would work by default:\n",
    "\n",
    "# Start example ------------\n",
    "\n",
    "# import numpy as np\n",
    "# from matchms.similarity import CosineGreedy\n",
    "# from matchms import calculate_scores\n",
    "\n",
    "# similarity_measure = CosineGreedy()\n",
    "# scores = calculate_scores(references, queries, similarity_measure)\n",
    "\n",
    "# This only for printing the results\n",
    "# for (reference, query, score) in scores:\n",
    "#     print(f\"Cosine score between {reference.get('id')} and {query.get('id')}\" +\n",
    "#           f\" is {score[0]:.2f} with {score[1]} matched peaks\")\n",
    "\n",
    "# End example --------------\n",
    "\n",
    "# Here I just break it down so you see what is happening behind the scenes\n",
    "# It is basically three function calls (the first two will collect the matching pairs, the third will score them - including normalization)\n",
    "# The time bottleneck is on the last function call (score_best_matches), as it operates on single spectra pairs\n",
    "# Storing the output of matching pairs in some dataframe (tensor) and then scoring them in batches would be much faster\n",
    "# So it is really the last function that needs to be changed\n",
    "# I managed to create a batch version of the first two functions but that did not hold any speedup\n",
    "# Plus it only worked on specific case - multiple spectra in the reference against a single spectrum in the query (not multiple vs multiple)\n",
    "\n",
    "# I am setting the mz_tolerance to 0.1, as this is probably the value we will use by default\n",
    "# That being said, in this exercise it just to cover all potential cases where we can have a peak from one spectrum matching several peaks in the other\n",
    "# Only one (the first) is then selected in the scoring function \n",
    "\n",
    "    # for spectrum_1 in references:\n",
    "    #     for spectrum_2 in queries:\n",
    "    #         spec1 = spectrum_1.peaks.to_numpy\n",
    "    #         spec2 = spectrum_2.peaks.to_numpy\n",
    "    #         matching_pairs = collect_peak_pairs(spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "    #                     shift=0.0, mz_power=0.0,\n",
    "    #                     intensity_power=1.0)\n",
    "    #         if matching_pairs is not None:\n",
    "    #             score = score_best_matches(matching_pairs, spec1, spec2,\n",
    "    #                                     0.0, 1.0)\n",
    "    #             print(score)\n",
    "    #         else: print(\"No matching pairs found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global a\n",
    "    # a = matches\n",
    "    # matches_op = find_matches_opt(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global b\n",
    "    # b = matches_op\n",
    "    # assert np.allclose(matches, matches_op)\n",
    "    \n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "# @numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking runtime\n",
    "\n",
    "Below is a small snippets to benchmark runtime of the collect_peak_pairs function and score_best_matches function.\n",
    "To do so we split the approach in two parts, first collecting and storing the matching pairs, second running the score function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for spectrum_1 in tqdm(references):\n",
    "#     for spectrum_2 in queries:\n",
    "#         spec1 = spectrum_1.peaks.to_numpy\n",
    "#         spec2 = spectrum_2.peaks.to_numpy\n",
    "        \n",
    "#         matching_pairs = collect_peak_pairs_opt(\n",
    "#                     spectrum_1.peaks.to_numpy, \n",
    "#                     spectrum_2.peaks.to_numpy, \n",
    "#                     0.1,\n",
    "#                     shift=0.0, mz_power=0.0,\n",
    "#                     intensity_power=1.0\n",
    "#         )\n",
    "#         if matching_pairs is not None:\n",
    "#             pairs_to_score_list.append([ matching_pairs, spectrum_1, spectrum_2])  \n",
    "# end_collect_peaks = time.time()\n",
    "# print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start_collect_peaks = time.time()\n",
    "# pairs_to_score_list = []\n",
    "# def fn(spectrum_1, spectrum_2):\n",
    "#     s1, s2 = spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy\n",
    "#     matching_pairs = collect_peak_pairs(s1, s2, 0.1,\n",
    "#                 shift=0.0, mz_power=0.0,\n",
    "#                 intensity_power=1.0)\n",
    "#     if matching_pairs is not None:\n",
    "#         score = score_best_matches(matching_pairs, s1, s2, 0.0, 1.0)\n",
    "#         if score is not None:\n",
    "#             return [matching_pairs, spectrum_1, spectrum_2, score]\n",
    "# pairs_to_score_list = Parallel(-1)(delayed(fn)(spectrum_1, spectrum_2) \n",
    "#                                    for spectrum_1, spectrum_2 in tqdm(product(references, queries), total=len(references) * len(queries)))\n",
    "# pairs_to_score_list = [e for e in pairs_to_score_list if e is not None] # Make sure if matching_pairs is missing, remove entry\n",
    "\n",
    "\n",
    "def find_matches_opt(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    a = tf.constant(spec1_mz)[...,None]\n",
    "    b = tf.constant(spec2_mz)[None,...]\n",
    "    a = tf.repeat(a, axis=1, repeats=b.shape[1])\n",
    "    b = tf.repeat(b, axis=0, repeats=a.shape[0])\n",
    "    c = tf.where(tf.abs(a - (b+shift)) <= tolerance)\n",
    "    matches = c.numpy().tolist()\n",
    "    return matches\n",
    "\n",
    "def collect_peak_pairs_opt(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    spec1 = tf.constant(spec1)\n",
    "    spec2 = tf.constant(spec2)\n",
    "\n",
    "    a = tf.constant(spec1[:, 0])[...,None]\n",
    "    b = tf.constant(spec2[:, 0])[None,...]\n",
    "\n",
    "    a_mat = tf.repeat(a, axis=1, repeats=b.shape[1])\n",
    "    b_mat = tf.repeat(b, axis=0, repeats=a.shape[0])\n",
    "    match_idx = tf.where(tf.abs(a_mat - (b_mat+shift)) <= tolerance)\n",
    "    \n",
    "    power_prod_spec1 = tf.gather(spec1[:,0], match_idx[:,0]) ** mz_power * tf.gather(spec1[:,1], match_idx[:,0]) ** intensity_power\n",
    "    power_prod_spec2 = tf.gather(spec2[:,0], match_idx[:,1]) ** mz_power * tf.gather(spec2[:,1], match_idx[:,1]) ** intensity_power\n",
    "\n",
    "    matching_pairs = tf.concat([tf.cast(match_idx, tf.float64), power_prod_spec1[...,None] * power_prod_spec2[...,None]], 1)\n",
    "    return matching_pairs.numpy()\n",
    "\n",
    "# for spectrum_1 in tqdm(references):\n",
    "#     for spectrum_2 in queries:\n",
    "#         spec1 = spectrum_1.peaks.to_numpy\n",
    "#         spec2 = spectrum_2.peaks.to_numpy\n",
    "        \n",
    "#         matching_pairs = collect_peak_pairs_opt(\n",
    "#                     spectrum_1.peaks.to_numpy, \n",
    "#                     spectrum_2.peaks.to_numpy, \n",
    "#                     0.1,\n",
    "#                     shift=0.0, mz_power=0.0,\n",
    "#                     intensity_power=1.0\n",
    "#         )\n",
    "#         if matching_pairs is not None:\n",
    "#             pairs_to_score_list.append([ matching_pairs, spectrum_1, spectrum_2])  \n",
    "# end_collect_peaks = time.time()\n",
    "# print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the matching pairs along with the spectra\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "# Very small example\n",
    "references = [spectrum_1, spectrum_3]\n",
    "queries = [spectrum_2, spectrum_4]\n",
    "\n",
    "# Realistic example\n",
    "# references = large_references[1000:100000]\n",
    "# queries = large_references[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Abs_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Abs]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/tf/cosine_example_Tornike.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e65222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/tf/cosine_example_Tornike.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m b_mat \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39madd(b_mat, \u001b[39m-\u001b[39mshift)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e65222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/tf/cosine_example_Tornike.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m a_mat\u001b[39m.\u001b[39mshape, b_mat\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e65222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/tf/cosine_example_Tornike.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m z \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mwhere(tf\u001b[39m.\u001b[39;49mabs(a_mat \u001b[39m-\u001b[39;49m b_mat) \u001b[39m<\u001b[39m tolerance)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e65222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f686f6d652f746f726e696b656f2f446f63756d656e74732f776f726b2f7363616c6578612f70616e67656161692f6f7074696d697a652d636f73696e652f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/tf/cosine_example_Tornike.ipynb#Y126sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# print(i, tf.reduce_mean(z))\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Abs_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Abs]"
     ]
    }
   ],
   "source": [
    "def spectra_peaks_to_tensor(spectra: list, fill: float) -> tf.Tensor:\n",
    "    sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "    sp = np.full((len(spectra), sp_max_shape, 2), fill, 'float32')\n",
    "    for i, s in enumerate(spectra):\n",
    "        sp[i, :len(s.peaks)] = s.peaks.to_numpy\n",
    "    sp = tf.constant(sp, tf.float32)\n",
    "    return sp\n",
    "import random\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "mz_power = 0.0\n",
    "intensity_power = 1.0\n",
    "\n",
    "NUM_R = 100\n",
    "NUM_Q = 10\n",
    "references = random.sample(large_references,NUM_R) # 1e6\n",
    "queries = random.sample(large_references,NUM_R) # 1e5\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    ref_sp = spectra_peaks_to_tensor(references, np.inf)\n",
    "    que_sp = spectra_peaks_to_tensor(queries, np.inf)\n",
    "    shift = 0\n",
    "    tolerance = .1\n",
    "    R,M,T = ref_sp.shape\n",
    "    Q,N,T = que_sp.shape\n",
    "\n",
    "    a = tf.constant(ref_sp[..., 0])[...,None]\n",
    "    b = tf.constant(que_sp[..., 0])[...,None]\n",
    "\n",
    "    a_mat = tf.repeat(a, axis=-1, repeats=N)\n",
    "    a_mat = a_mat[None,...]\n",
    "    a_mat = tf.repeat(a_mat, axis=0, repeats=Q)\n",
    "    a_mat = tf.transpose(a_mat, [1,0,2,3])\n",
    "\n",
    "    b_mat = tf.repeat(b, axis=-1, repeats=M)\n",
    "    b_mat = tf.transpose(b_mat, [0,2,1])\n",
    "    b_mat = b_mat[None,...]\n",
    "    b_mat = tf.repeat(b_mat, axis=0, repeats=R)\n",
    "    b_mat = tf.add(b_mat, -shift)\n",
    "    a_mat.shape, b_mat.shape\n",
    "\n",
    "    match = tf.where(tf.abs(a_mat - b_mat) < tolerance)\n",
    "    \n",
    "    power_prod_spec1 = tf.gather(a_mat[:,0], match[:,0]) ** mz_power * tf.gather(a_mat[:,1], match[:,0]) ** intensity_power\n",
    "    power_prod_spec2 = tf.gather(b_mat[:,0], match[:,1]) ** mz_power * tf.gather(b_mat[:,1], match[:,1]) ** intensity_power\n",
    "\n",
    "    match = tf.cast(match, tf.float32)\n",
    "    matching_pairs = tf.concat([match, power_prod_spec1[...,None] * power_prod_spec2[...,None]], 1)\n",
    "    # print(i, tf.reduce_mean(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# match_idx = tf.where(tf.abs(a_mat - (b_mat+shift)) <= tolerance)\n",
    "\n",
    "# power_prod_spec1 = tf.gather(spec1[:,0], match_idx[:,0]) ** mz_power * tf.gather(spec1[:,1], match_idx[:,0]) ** intensity_power\n",
    "# power_prod_spec2 = tf.gather(spec2[:,0], match_idx[:,1]) ** mz_power * tf.gather(spec2[:,1], match_idx[:,1]) ** intensity_power\n",
    "\n",
    "# matching_pairs = tf.concat([tf.cast(match_idx, tf.float64), power_prod_spec1[...,None] * power_prod_spec2[...,None]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # for i, idx in enumerate(idx1):\n",
    "    #     power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "    #     power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "    #     matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    # return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "# collect_peak_pairs(\n",
    "#     spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "#     shift=0.0, mz_power=0.0,\n",
    "#     intensity_power=1.0\n",
    "# ), collect_peak_pairs_opt(\n",
    "#     spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy, 0.1,\n",
    "#     shift=0.0, mz_power=0.0,\n",
    "#     intensity_power=1.0\n",
    "# )\n",
    "\n",
    "# shift = 0\n",
    "# tolerance = .1\n",
    "# mz_power = 0.0\n",
    "# intensity_power = 1.0\n",
    "\n",
    "# spec1 = tf.constant(spec1)\n",
    "# spec2 = tf.constant(spec2)\n",
    "\n",
    "# a = tf.constant(spec1[:, 0])[...,None]\n",
    "# b = tf.constant(spec2[:, 0])[None,...]\n",
    "\n",
    "# a_mat = tf.repeat(a, axis=1, repeats=b.shape[1])\n",
    "# b_mat = tf.repeat(b, axis=0, repeats=a.shape[0])\n",
    "# match_idx = tf.where(tf.abs(a - (b+shift)) <= tolerance)\n",
    "\n",
    "# power_prod_spec1 = tf.gather(spec1[:,0], match_idx[:,0]) ** mz_power * tf.gather(spec1[:,1], match_idx[:,0]) ** intensity_power\n",
    "# power_prod_spec2 = tf.gather(spec2[:,0], match_idx[:,1]) ** mz_power * tf.gather(spec2[:,1], match_idx[:,1]) ** intensity_power\n",
    "\n",
    "# tf.concat([tf.cast(match_idx, tf.float64), power_prod_spec1[...,None] * power_prod_spec2[...,None]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(0, 2), dtype=int64, numpy=array([], shape=(0, 2), dtype=int64)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolerance = 0.1\n",
    "a = spectrum_1.peaks.to_numpy[:,0]\n",
    "b = spectrum_2.peaks.to_numpy[:,0]\n",
    "a = tf.constant(a)[None,...]\n",
    "b = tf.constant(b)[...,None]\n",
    "a = tf.repeat(a, axis=0, repeats=b.shape[0])\n",
    "b = tf.repeat(b, axis=1, repeats=a.shape[1])\n",
    "c = tf.where(tf.abs(a - b) <= tolerance)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] ndims must be == 2: 1 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(a)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m b \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(b)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cosine_example_Tornike.ipynb#Y100sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a \u001b[39m@\u001b[39;49m b\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/pb/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] and In[1] ndims must be == 2: 1 [Op:MatMul]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can score the matching pairs\n",
    "start_score = time.time()\n",
    "# def fn(matching_pairs, spectrum_1, spectrum_2):\n",
    "#     score = score_best_matches(matching_pairs, spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy,\n",
    "#                                 0.0, 1.0)\n",
    "#     return score\n",
    "\n",
    "# scores = Parallel(-1)(delayed(fn)(matching_pairs, spectrum_1, spectrum_2) \n",
    "#                       for matching_pairs, spectrum_1, spectrum_2 in tqdm(pairs_to_score_list, total=len(pairs_to_score_list)))\n",
    "scores = []\n",
    "for matching_pairs, spectrum_1, spectrum_2 in tqdm(pairs_to_score_list):\n",
    "    scores.append(score_best_matches(matching_pairs, spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy,\n",
    "                                0.0, 1.0))\n",
    "\n",
    "end_score = time.time()\n",
    "print(\"Time to score matching pairs: \", end_score - start_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(pairs_to_score_list, Path('pairs_to_score_list.pickle').open('wb'))\n",
    "# pickle.dump(scores, Path('scores.pickle').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ld = pickle.load(Path('scores.pickle').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(scores_ld) == np.array(scores)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unoptimized\n",
    "``` \n",
    "100%|██████████| 91698/91698 [00:56<00:00, 1627.05it/s]\n",
    "Time to collect matching pairs:  56.94396376609802\n",
    "100%|██████████| 635365/635365 [00:21<00:00, 29557.14it/s]\n",
    "Time to score matching pairs:  21.498287439346313\n",
    "```\n",
    "\n",
    "Optimized (CPU parallelism, 12 CPUs)\n",
    "``` \n",
    "100%|██████████| 916980/916980 [00:20<00:00, 44429.67it/s]\n",
    "Time to collect matching pairs:  21.796888828277588\n",
    "100%|██████████| 635365/635365 [00:20<00:00, 30734.33it/s]\n",
    "Time to score matching pairs:  21.340625762939453\n",
    "```\n",
    "\n",
    "Optimized (CPU parallelism 12 CPUs)\n",
    "```\n",
    "100%|██████████| 916980/916980 [00:30<00:00, 29640.48it/s]\n",
    "Time to collect matching pairs:  31.654369831085205\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
