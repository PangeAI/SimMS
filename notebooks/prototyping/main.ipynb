{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports\n",
    "# import tensorflow as tf\n",
    "# print(\"GPU available\", tf.test.is_gpu_available())\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import math\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "from matchms import Spectrum\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df, limit=None):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    # Argh, This function is annoyingly slow. Added simple parallelization.\n",
    "    \n",
    "    # for index, row in spectra_df.iterrows():\n",
    "    def fn(index, row):\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                'precursor_mz': precursor_mz, \n",
    "                                'smiles': smiles, \n",
    "                                'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        return sp\n",
    "    if limit is not None:\n",
    "        spectra_df = spectra_df.head(limit)\n",
    "    spectra = Parallel(-2)(delayed(fn)(index, row) for index, row in tqdm(spectra_df.iterrows(), total=len(spectra_df)) )\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    return spectra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2331.65it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_spectra_df_path = Path(\"data/input/example_dataset_tornike.csv\")\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "large_references = get_ref_spectra_from_df(ref_spectra_df, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 1048576\n"
     ]
    }
   ],
   "source": [
    "R = 1024 * 4\n",
    "Q = 1024 * 4\n",
    "references = large_references[Q:Q+R]\n",
    "queries = large_references[:Q]\n",
    "\n",
    "print(f\"Total iterations: {len(queries) * len(references)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "                # print((peak1_idx, peak2_idx))\n",
    "    # print(matches)\n",
    "    return matches\n",
    "\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def score_best_matches(matching_pairs: np.ndarray, spec1: np.ndarray,\n",
    "                       spec2: np.ndarray, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0) -> Tuple[float, int]:\n",
    "    \"\"\"Calculate cosine-like score by multiplying matches. Does require a sorted\n",
    "    list of matching peaks (sorted by intensity product).\"\"\"\n",
    "    score = float(0.0)\n",
    "    used_matches = int(0)\n",
    "    used1 = set()\n",
    "    used2 = set()\n",
    "    for i in range(matching_pairs.shape[0]):\n",
    "        if not matching_pairs[i, 0] in used1 and not matching_pairs[i, 1] in used2:\n",
    "            score += matching_pairs[i, 2]\n",
    "            used1.add(matching_pairs[i, 0])  # Every peak can only be paired once\n",
    "            used2.add(matching_pairs[i, 1])  # Every peak can only be paired once\n",
    "            # print(i, matching_pairs[i,0], matching_pairs[i,1], used_matches, score)\n",
    "            used_matches += 1\n",
    "\n",
    "    # Normalize score:\n",
    "    spec1_power = spec1[:, 0] ** mz_power * spec1[:, 1] ** intensity_power    \n",
    "    spec2_power = spec2[:, 0] ** mz_power * spec2[:, 1] ** intensity_power\n",
    "\n",
    "    # print(spec1_power)\n",
    "    # print(spec2_power)\n",
    "    # raise\n",
    "    score_norm = (np.sum(spec1_power ** 2) ** 0.5 * np.sum(spec2_power ** 2) ** 0.5)\n",
    "    # print(score, score_norm, used_matches)\n",
    "    score = score/score_norm\n",
    "    # print(score, \"/\", score_norm)\n",
    "    # raise\n",
    "    return score, used_matches\n",
    "\n",
    "@numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance apart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global a\n",
    "    # a = matches\n",
    "    # matches_op = find_matches_opt(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global b\n",
    "    # b = matches_op\n",
    "    # assert np.allclose(matches, matches_op)\n",
    "    \n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        # print((idx, idx2[i], power_prod_spec1 * power_prod_spec2))\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:23<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to collect matching pairs:  83.73173379898071\n",
      "[[ 4.  4.  5. ... 31. 35. 43.]\n",
      " [ 4.  5.  6. ... 30. 34. 42.]\n",
      " [ 4.  5.  5. ... 23. 27. 34.]\n",
      " ...\n",
      " [ 1.  2.  2. ...  4.  7.  9.]\n",
      " [ 1.  1.  1. ...  4.  7.  9.]\n",
      " [ 1.  1.  1. ...  4.  7.  8.]]\n",
      "[[6.064e-03 6.568e-03 8.362e-03 ... 9.214e-01 9.466e-01 9.786e-01]\n",
      " [2.267e-03 2.512e-03 3.502e-03 ... 7.990e-01 8.345e-01 8.921e-01]\n",
      " [1.905e-03 1.979e-03 2.310e-03 ... 5.873e-01 6.283e-01 7.039e-01]\n",
      " ...\n",
      " [5.589e-05 5.865e-05 6.088e-05 ... 1.670e-03 9.333e-03 3.193e-02]\n",
      " [3.007e-05 3.019e-05 2.956e-05 ... 1.505e-03 9.153e-03 3.166e-02]\n",
      " [9.118e-06 9.154e-06 8.963e-06 ... 1.113e-03 7.699e-03 2.706e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/PangeAI/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/PangeAI/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_outp[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/PangeAI/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#W4sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mdata/grid_outp.npy\u001b[39m\u001b[39m'\u001b[39m, grid_outp)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/PangeAI/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "def spectra_peaks_to_tensor(spectra: list, fill: float):\n",
    "    sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "    sp = np.full((len(spectra), sp_max_shape, 2), fill, 'float32')\n",
    "    # batch = np.zeros(len(spectra),dtype=np.uint64)\n",
    "    for i, s in enumerate(spectra):\n",
    "        sp[i, :len(s.peaks)] = s.peaks.to_numpy\n",
    "        # batch[i] = len(s.peaks)\n",
    "    return sp\n",
    "\n",
    "references_batch = spectra_peaks_to_tensor(references, fill=-1e6)\n",
    "queries_batch = spectra_peaks_to_tensor(queries, fill=-1e6)\n",
    "\n",
    "start_collect_peaks = time.time()\n",
    "pairs_to_score_list = []\n",
    "scores = []\n",
    "grid_outp = np.full((len(references), len(queries), 3), \n",
    "                    fill_value=-1, \n",
    "                    dtype='float32')\n",
    "for i,spectrum_1 in tqdm(enumerate(references),total=len(references)):\n",
    "    for j,spectrum_2 in enumerate(queries):\n",
    "        spec1 = spectrum_1.peaks.to_numpy\n",
    "        spec2 = spectrum_2.peaks.to_numpy\n",
    "        \n",
    "        matching_pairs = collect_peak_pairs(\n",
    "                    spectrum_1.peaks.to_numpy, \n",
    "                    spectrum_2.peaks.to_numpy, \n",
    "                    tolerance=0.1,\n",
    "                    shift=0.0, \n",
    "                    mz_power=0.0,\n",
    "                    intensity_power=1.0\n",
    "        )\n",
    "        if matching_pairs is not None:\n",
    "            # Store in grid\n",
    "            matching_pairs = matching_pairs[np.argsort(matching_pairs[:, 2])[::-1], :] \n",
    "            pairs_to_score_list.append([ matching_pairs, spectrum_1, spectrum_2]) \n",
    "            # for matching_pairs, spectrum_1, spectrum_2 in tqdm(pairs_to_score_list):\n",
    "            score = score_best_matches(matching_pairs, spec1, spec2, 0.0, 1.0)\n",
    "            grid_outp[i,j,0] = score[0]\n",
    "            grid_outp[i,j,1] = score[1]\n",
    "            # grid_outp[i,j,3] = scores[]\n",
    "            # grid_outp[i,j,4] = matching_pairs[0,2]\n",
    "            scores.append(score)\n",
    "end_collect_peaks = time.time()\n",
    "print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)\n",
    "print(grid_outp[...,1])\n",
    "print(grid_outp[...,0])\n",
    "np.save('data/grid_outp.npy', grid_outp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
