{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates the performance of just parallelizing the similarity over CPUs (**not GPUs**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores 12\n"
     ]
    }
   ],
   "source": [
    "# We compare pairwise similarity performance on `spectra_file`\n",
    "# We can use pickled version for much faster loading times\n",
    "spectra_file = 'GNPS-LIBRARY-default-filter-nmax-2048.pickle'\n",
    "\n",
    "# We take a random sample of spectra from said file\n",
    "\n",
    "# Minimum size:\n",
    "chunk_sizes_min = 32\n",
    "\n",
    "# Maximum size\n",
    "chunk_sizes_max = 1024\n",
    "\n",
    "# how many points to evaluate (in logspace) between min and max\n",
    "num_evals = 15\n",
    "\n",
    "! echo Number of CPU cores $(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tornikeo/micromamba/envs/pb2/lib/python3.11/site-packages/sparsestack/StackedSparseArray.py:4: DeprecationWarning: Please use `get_index_dtype` from the `scipy.sparse` namespace, the `scipy.sparse.sputils` namespace is deprecated.\n",
      "  from scipy.sparse.sputils import get_index_dtype\n",
      "Downloading data from 'https://github.com/tornikeo/cudams/releases/download/samples-0.1/GNPS-LIBRARY-default-filter-nmax-2048.pickle' to file '/home/tornikeo/.cache/pooch/2243cebc54a3035914aa78c57585f0d1-GNPS-LIBRARY-default-filter-nmax-2048.pickle'.\n",
      "100%|██████████████████████████████████████| 86.7M/86.7M [00:00<00:00, 161GB/s]\n",
      "SHA256 hash of downloaded file: 9797fa1068f59c6e2a2e005c44d7322f07b6cb08e125c9d5c2cc60bdfe3771e6\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "/tmp/ipykernel_393455/3895481198.py:16: ResourceWarning: unclosed file <_io.BufferedReader name='/home/tornikeo/.cache/pooch/2243cebc54a3035914aa78c57585f0d1-GNPS-LIBRARY-default-filter-nmax-2048.pickle'>\n",
      "  spectra = pickle.load(open(download(spectra_file),'rb'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from cudams.utils import argbatch, Timer\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "from cudams.utils import download\n",
    "from joblib import Parallel, delayed\n",
    "from matchms.filtering import default_filters, normalize_intensities, reduce_to_number_of_peaks\n",
    "from matchms.importing import load_from_mgf\n",
    "from matchms.similarity import CosineGreedy\n",
    "from matchms import calculate_scores\n",
    "from cudams.utils import Timer\n",
    "\n",
    "spectra = pickle.load(open(download(spectra_file),'rb'))\n",
    "spectra = spectra[:chunk_sizes_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 67.54it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = np.round(np.logspace(\n",
    "    np.log2(chunk_sizes_min), \n",
    "    np.log2(chunk_sizes_max), \n",
    "    num=num_evals, \n",
    "    base=2, \n",
    "    endpoint=True)\n",
    ").astype(int)\n",
    "\n",
    "times = []\n",
    "pairs = []\n",
    "kernel = CosineGreedy()\n",
    "\n",
    "def loop(chunk_size):\n",
    "    references = spectra[:chunk_size]\n",
    "    queries = spectra[:chunk_size]\n",
    "    with Timer() as timer:\n",
    "        kernel.matrix(references, queries)\n",
    "    return timer.duration, len(references) * len(queries) # All samples\n",
    "\n",
    "# Do it in parallel, each experiment gets own CPU, so comparison is still fair.\n",
    "data = Parallel(-1)(delayed(loop)(chunk_size) for chunk_size in tqdm(chunk_sizes))\n",
    "\n",
    "## Not sure if Joblib would interfere with Numba's jit prange... \n",
    "# data = (loop(chunk_size) for chunk_size in tqdm(chunk_sizes))\n",
    "times, pairs = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"pairs\": [\n",
      "  1024,\n",
      "  1681,\n",
      "  2809,\n",
      "  4489,\n",
      "  7396,\n",
      "  12100,\n",
      "  19881,\n",
      "  32761,\n",
      "  53824,\n",
      "  88209,\n",
      "  144400,\n",
      "  237169,\n",
      "  389376,\n",
      "  638401,\n",
      "  1048576\n",
      " ],\n",
      " \"times\": [\n",
      "  4.61960701299904,\n",
      "  4.848240357001487,\n",
      "  4.353743239000323,\n",
      "  4.6457689220005705,\n",
      "  4.787713708999945,\n",
      "  5.658327465000184,\n",
      "  6.151166523999564,\n",
      "  7.604971161999856,\n",
      "  9.928251830999216,\n",
      "  11.936628774001292,\n",
      "  17.188605341001676,\n",
      "  21.95269652499701,\n",
      "  33.71507874500094,\n",
      "  54.35259559399856,\n",
      "  101.6103339609981\n",
      " ],\n",
      " \"device\": \"NVIDIA GeForce RTX 2070 with Max-Q Design\",\n",
      " \"nproc\": 12\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "benchmark_summary = dict(\n",
    "        pairs=pairs,\n",
    "        times=times,\n",
    "        device=torch.cuda.get_device_name(),\n",
    "        nproc=os.cpu_count(),    \n",
    "    )\n",
    "print(json.dumps(benchmark_summary,indent=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
